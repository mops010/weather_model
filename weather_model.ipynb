{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owXyDqNelVld"
   },
   "source": [
    "# Климат (кейс МППО 2023-24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Библиотеки, Функции, Классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import optuna\n",
    "import prophet\n",
    "import warnings\n",
    "import lightgbm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna.integration.lightgbm as lgb\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from prophet import Prophet\n",
    "from typing import Optional\n",
    "from itertools import product\n",
    "from lightgbm import LGBMRegressor\n",
    "# from etna.datasets import TSDataset\n",
    "from datetime import datetime, timedelta\n",
    "from holidays.holiday_base import HolidayBase\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "def create_new_data():\n",
    "    \n",
    "    # Позиции разделителей\n",
    "    sep_param=[5, 5, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 5, 2, 2, \n",
    "               3, 2, 3, 2, 3, 2, 4, 2, 3, 2, 2, 3, 2, 2, 7, 2, 6, 2, 6, 2, 6, 2, 6, 2, 6, 2, 6, 2, 6, 2, 2, 6, 2,\n",
    "               6, 2, 6, 2, 6, 2, 6, 2, 2, 4, 2, 8, 2, 2, 6, 2, 7, 2, 7, 2, 3, 2, 5, 2, 2]\n",
    "\n",
    "    count = 1\n",
    "    for name_file in os.listdir('/Users/andreyboriskin/PycharmProjects/predprof/dat_files'):\n",
    "        folder = '/Users/andreyboriskin/PycharmProjects/predprof/new_dat_files/'\n",
    "        fd_filename = '/Users/andreyboriskin/PycharmProjects/predprof/dat_files/' + name_file\n",
    "        fn_new = open(f'{folder + name_file[:5]}.csv', 'w', encoding='utf-8')\n",
    "        for line in open(fd_filename, encoding='utf-8', errors='ignore'):\n",
    "            line_new = line[:sep_param[0]]\n",
    "            item_position = sep_param[0]\n",
    "            for i in range(1,len(sep_param)-1):\n",
    "                line_new += ',' + line[item_position+1:item_position+sep_param[i]]\n",
    "                item_position += sep_param[i]\n",
    "            fn_new.write(line_new + '\\n')\n",
    "        fn_new.close()\n",
    "        print(f'/r{count}/405, {name_file[:5]}.csv создан', end='')\n",
    "        count += 1\n",
    "\n",
    "        \n",
    "def create_df(file_name: str) -> pd.core.frame.DataFrame:\n",
    "    folder = '/Users/andreyboriskin/PycharmProjects/predprof/new_dat_files/'\n",
    "    \n",
    "    df = pd.read_csv(folder + file_name, sep=',', header=None, low_memory=False)\n",
    "    new_name = dict()\n",
    "    for i in range(len(df1.comment[:90])):\n",
    "        new_name[i] = df1.comment[i]\n",
    "    df = df.rename(columns=new_name)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def list_remove(ls, ls_remove):\n",
    "    for i in ls_remove:\n",
    "        ls.remove(i)\n",
    "        \n",
    "    return ls\n",
    "\n",
    "\n",
    "def root_mean_squared_error(act, pred):\n",
    "    diff = pred - act # находим разницу между прогнозируемыми и наблюдаемыми значениями\n",
    "    differences_squared = diff ** 2 # возводим в квадрат\n",
    "    mean_diff = differences_squared.mean() # находим среднее значение\n",
    "    rmse_val = np.sqrt(mean_diff) # извлекаем квадратный корень\n",
    "    \n",
    "    return rmse_val\n",
    "\n",
    "\n",
    "def assign_ethnicity(df):\n",
    "    mn = []\n",
    "    for i in range(len(df)):\n",
    "        mn.append(f\"{df.iloc[:, [1]].loc[i][0]}-{df.iloc[:, [2]].loc[i][0]}-{df.iloc[:, [3]].loc[i][0]}\")\n",
    "        \n",
    "    return mn\n",
    "\n",
    "\n",
    "def create_massive_df(filename: str) -> pd.DataFrame:\n",
    "    \n",
    "    df = pd.read_csv(f'/Users/andreyboriskin/PycharmProjects/predprof/new_dat_files/{filename}', header=None)\n",
    "\n",
    "    if df.shape[0] == 166552:\n",
    "    \n",
    "        df = df.drop(df.loc[df[4] != 15].index)\n",
    "        df.index = range(df.shape[0])\n",
    "        df[90] = assign_ethnicity(df)\n",
    "        \n",
    "        return df.loc[:, [0, 90, 41, 47, 59, 75]]\n",
    "\n",
    "\n",
    "class suppress_stdout_stderr:\n",
    "    '''\n",
    "    A context manager for doing a \"deep suppression\" of stdout and stderr in\n",
    "    Python, i.e. will suppress all print, even if the print originates in a\n",
    "    compiled C/Fortran sub-function.\n",
    "       This will not suppress raised exceptions, since exceptions are printed\n",
    "    to stderr just before a script exits, and after the context manager has\n",
    "    exited (at least, I think that is why it lets exceptions through).\n",
    "\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        # Open a pair of null files\n",
    "        self.null_fds = [os.open(os.devnull, os.O_RDWR) for x in range(2)]\n",
    "        # Save the actual stdout (1) and stderr (2) file descriptors.\n",
    "        self.save_fds = [os.dup(1), os.dup(2)]\n",
    "\n",
    "    def __enter__(self):\n",
    "        # Assign the null pointers to stdout and stderr.\n",
    "        os.dup2(self.null_fds[0], 1)\n",
    "        os.dup2(self.null_fds[1], 2)\n",
    "\n",
    "    def __exit__(self, *_):\n",
    "        # Re-assign the real stdout/stderr back to (1) and (2)\n",
    "        os.dup2(self.save_fds[0], 1)\n",
    "        os.dup2(self.save_fds[1], 2)\n",
    "        # Close the null files\n",
    "        for fd in self.null_fds + self.save_fds:\n",
    "            os.close(fd)\n",
    "            \n",
    "            \n",
    "\n",
    "class OptunaLGBMRegressor:\n",
    "    \"\"\"\n",
    "    A wrapper class for the LightGBM Regressor with Optuna for hyperparameters tuning\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators: int,\n",
    "        learning_rate: float = 0.01,\n",
    "        metric: str = 'rmse',\n",
    "        cat_columns: str = 'auto',\n",
    "        seed: int = 42\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes a new instance of the OptunaLGBMRegressor class\n",
    "        \"\"\"\n",
    "        self.params = {\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"objective\": \"regression\",\n",
    "            \"verbosity\": -1,\n",
    "            \"metric\": metric,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"boosting_type\": 'gbdt',\n",
    "            \"random_state\": seed\n",
    "        }\n",
    "        self.cat_columns = cat_columns\n",
    "        self.model = None\n",
    "        self.features = None\n",
    "        self.is_fitted_ = False\n",
    "\n",
    "    def _to_datasets(\n",
    "        self, x_train: pd.DataFrame, y_train: np.ndarray, x_val: pd.DataFrame, y_val: np.ndarray\n",
    "    ) -> (lightgbm.Dataset, lightgbm.Dataset):\n",
    "        \"\"\"\n",
    "        Converts Pandas DataFrames to LightGBM Datasets\n",
    "        \"\"\"\n",
    "        self.features = list(x_train.columns)\n",
    "        X_val = x_val[self.features].copy()\n",
    "        dtrain = lightgbm.Dataset(x_train, label=y_train, categorical_feature=self.cat_columns)\n",
    "        dval = lightgbm.Dataset(X_val, label=y_val, categorical_feature=self.cat_columns)\n",
    "\n",
    "        return dtrain, dval     \n",
    "\n",
    "    def fit(self, X_train: pd.DataFrame, y_train: np.ndarray, X_val: pd.DataFrame, y_val: np.ndarray) -> None:\n",
    "        dtrain, dval = self._to_datasets(X_train, y_train, X_val, y_val)\n",
    "        \n",
    "        self.model = lgb.tuner.train(\n",
    "            self.params,\n",
    "            dtrain,\n",
    "            valid_sets=[dtrain, dval],\n",
    "        )\n",
    "        \n",
    "        self.is_fitted_ = True\n",
    "\n",
    "    def predict(self, X_test: pd.DataFrame) -> np.ndarray:\n",
    "        assert self.is_fitted_, 'Model is not fitted!'\n",
    "        return self.model.predict(X_test[self.features], num_iteration=self.model.best_iteration)\n",
    "\n",
    "\n",
    "class ProphetsEnsemble:\n",
    "    \"\"\"An ensemble of Prophet models with different aggregation functions and frequencies.\"\"\"\n",
    "\n",
    "    def __init__(self, freq: str, levels: list, agg_fn: list, holidays_getter: HolidayBase = None):\n",
    "        \"\"\"Initializes an ensemble of Prophet models.\"\"\"\n",
    "        self.freq = freq\n",
    "        self.levels = ['_'.join(x) for x in product(levels, agg_fn)]\n",
    "        self.h_getter = holidays_getter\n",
    "        self.prophets_ = dict()\n",
    "        self.is_fitted_ = False\n",
    "    \n",
    "    @staticmethod\n",
    "    def _resample(data: pd.DataFrame, freq: str, how: str) -> pd.DataFrame:\n",
    "        \"\"\"Resamples a time series DataFrame.\"\"\"\n",
    "        if how not in ['median', 'mean', 'sum']:\n",
    "            raise NotImplementedError(f'Unknown function {how}. Only [median, mean, sum] are supported.') \n",
    "        return data.set_index('ds').resample(freq).agg(how).reset_index(drop=False)\n",
    "\n",
    "    @staticmethod\n",
    "    def _merge_key_gen(x, level: str) -> str:\n",
    "        \"\"\"Generates a key for merging DataFrames based on the frequency.\"\"\"\n",
    "        freq = re.sub('[\\d]', '', level.split('_')[0])\n",
    "        if freq == 'H':\n",
    "            return f'{x.year}-{x.month}-{x.day}-{x.hour}'\n",
    "        elif freq in ['D', 'M']:\n",
    "            return f'{x.year}-{x.month}-{x.day}' if freq == 'D' else f'{x.year}-{x.month}'\n",
    "        elif freq == 'W':\n",
    "            return f'{x.isocalendar().year}-{x.isocalendar().week}'\n",
    "        raise NotImplementedError(f'Only [H, D, W, M] are supported. {freq} was recieved as input!')\n",
    "    \n",
    "    def _get_holidays(self, data: pd.DataFrame) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Extracts holidays from the data.\"\"\"\n",
    "        if self.h_getter is None:\n",
    "            return None\n",
    "        holidays = data[['ds']].copy()\n",
    "        holidays['holiday'] = holidays['ds'].apply(self.h_getter.get)\n",
    "        return holidays.dropna()\n",
    "    \n",
    "    def _fit_level(self, data: pd.DataFrame, level: str) -> None:\n",
    "        \"\"\"Fits a Prophet model for a specific aggregation level.\"\"\"\n",
    "        resampled = self._resample(data, *level.split('_')) if level != self.freq else data.copy()\n",
    "        fb = Prophet(holidays=self._get_holidays(resampled))\n",
    "        with suppress_stdout_stderr():\n",
    "            fb.fit(resampled)\n",
    "        self.prophets_[level] = fb\n",
    "        \n",
    "    def _predict_level(self, periods: int, level: str) -> pd.DataFrame:\n",
    "        \"\"\"Makes predictions for a specific aggregation level.\"\"\"\n",
    "        fb = self.prophets_[level]\n",
    "        df = fb.make_future_dataframe(periods=periods, freq=level.split('_')[0])\n",
    "        forecasts = fb.predict(df)\n",
    "        forecasts.columns = [f'{x}_{level}' for x in forecasts.columns]\n",
    "        return forecasts\n",
    "    \n",
    "    def _combine_levels(self, base_df: pd.DataFrame, data: pd.DataFrame, level: str) -> pd.DataFrame:\n",
    "        \"\"\"Combines predictions from different aggregation levels.\"\"\"\n",
    "        key = lambda x: self._merge_key_gen(x, level)\n",
    "        return (\n",
    "            base_df.assign(key=base_df['ds'].apply(key))\n",
    "            .merge(data.assign(key=data[f'ds_{level}'].apply(key)), on='key', how='left')\n",
    "            .drop(['key', f'ds_{level}'], axis=1)\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def _drop_redundant(data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Drops redundant features from the DataFrame.\"\"\"\n",
    "        redundant = [col for col in data.columns if col != 'ds' and 'yhat' not in col and len(data[col].unique()) == 1]\n",
    "        return data.drop(redundant, axis=1)\n",
    "    \n",
    "    def fit(self, data: pd.DataFrame) -> None:\n",
    "        \"\"\"Fits the Prophet models for all aggregation levels.\"\"\"\n",
    "        for level in tqdm([self.freq] + self.levels, 'Fitting prophets...'):\n",
    "            self._fit_level(data, level)\n",
    "        self.is_fitted_ = True\n",
    "            \n",
    "    def forecast(self, periods: int) -> pd.DataFrame:\n",
    "        \"\"\"Makes forecasts for all aggregation levels and combines them.\"\"\"\n",
    "        assert self.is_fitted_, 'Model is not fitted'\n",
    "        forecasts = [self._predict_level(periods, level) for level in tqdm([self.freq] + self.levels, 'Forecasting...')]\n",
    "        \n",
    "        forecast = forecasts[0].rename(columns={f'ds_{self.freq}': 'ds'})\n",
    "        for level, fore in zip(self.levels, forecasts[1:]):\n",
    "            forecast = self._combine_levels(forecast, fore, level)\n",
    "            \n",
    "        return self._drop_redundant(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Создание общего DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "yUDTa3jwlawZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filelink = 'Srok8c.ddl'\n",
    "# ddl_data = open(filelink,'r', encoding='cp1251').read()\n",
    "# # Сохраняем в кодировке utf-8\n",
    "# fn = open('Srok8c.ddl','w', encoding='utf-8')\n",
    "# fn.write(ddl_data)\n",
    "# fn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "2cjKuobBqQZX",
    "outputId": "d5bef7fc-b410-476e-f8ff-c55382e78603",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt1 = open('Srok8c.ddl','r').read() \n",
    "dt1 = dt1[dt1.find('KEY'):dt1.rfind('\\n')].split('\\n')\n",
    "dt2 = []\n",
    "for i in range(len(dt1)):\n",
    "  if dt1[i][:2] != '//' and dt1[i][1:3] != '//' and dt1[i][2:4] != '//':\n",
    "    tmp = dt1[i].split()\n",
    "    if tmp[4] == 'NA;':\n",
    "      tmp[3] += ';'\n",
    "      tmp.pop(4)\n",
    "    tmp[2] = tmp[2][3:-1]\n",
    "    if tmp[2].count(',') > 0:\n",
    "      tmp[2] = list(map(int, tmp[2].split(',')))[0]\n",
    "    tmp[3] = tmp[3][3:-2]\n",
    "    tmp[4] = ''\n",
    "    for j in range(5, len(tmp)):\n",
    "      tmp[4] += tmp[j] + ' '\n",
    "    tmp[4] = tmp[4][:-1]\n",
    "    dt2.append(tmp[:5])\n",
    "df1 = pd.DataFrame(dt2,columns=['keys', 'name', 'fa', 'pc', 'comment'])\n",
    "df1.fa = df1.fa.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = create_df('27612.csv')\n",
    "df.drop(['Признак качества'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(df.loc[df['Срок по Гринвичу'] != 15].index)\n",
    "df.index = range(df.shape[0])\n",
    "df['date'] = assign_ethnicity(df)\n",
    "df['date'] = pd.to_datetime(df.date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Создание временного ряда с помощью модели улучшенной Prophet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Температура"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_te = df.copy()\n",
    "df_te = df_te.rename(columns={'Температура воздуха по сухому терм-ру': 'y'})\n",
    "df_te.drop(df_te.loc[df_te['y'] == '     '].index, inplace=True)\n",
    "df_te['y'] = df_te['y'].astype('float64')\n",
    "data = pd.DataFrame(columns=['ds', 'y'])\n",
    "data['ds'] = df_te.date\n",
    "data['y'] = df_te.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_series = data # [data.ds < (data.ds.max() - timedelta(days=30))]\n",
    "# test_series = data[data.ds >= (data.ds.max() - timedelta(days=30))].drop(['y'], axis=1)\n",
    "start_date = '2022-12-31'\n",
    "end_date = '2023-01-07'\n",
    "\n",
    "start = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "end = datetime.strptime(end_date, '%Y-%m-%d')   \n",
    "\n",
    "daterange = [(start + timedelta(days=x)).strftime('%Y-%m-%d') for x in range(0, (end-start).days)]\n",
    "new_test_series = pd.DataFrame(pd.to_datetime(daterange), columns=['ds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:34:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:34:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "fb_te = prophet.Prophet()\n",
    "\n",
    "with suppress_stdout_stderr():\n",
    "    fb_te.fit(train_series)\n",
    "\n",
    "predictions = fb_te.make_future_dataframe(periods=len(new_test_series), freq='D')\n",
    "forecast = fb_te.predict(predictions)\n",
    "\n",
    "# v_fb_df = test_series.copy()\n",
    "# v_fb_df = v_fb_df.merge(forecast[['ds', 'yhat']], on='ds', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'fb_model_te.h5py'\n",
    "with open('/Users/andreyboriskin/PycharmProjects/predprof/models/model_te/' + filename, 'wb') as file:\n",
    "\tpickle.dump(fb_te, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-06 20:35:36,508] A new study created in memory with name: no-name-e421168c-2826-4988-a4eb-faa35c48140d\n",
      "\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction, val_score: inf:   0%|                   | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.822806:   0%|              | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.822806:  14%|8     | 1/7 [00:00<00:03,  1.53it/s]\u001b[A[I 2024-02-06 20:35:37,164] Trial 0 finished with value: 0.8228058789572678 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.8228058789572678.\n",
      "\n",
      "feature_fraction, val_score: 0.822806:  14%|8     | 1/7 [00:00<00:03,  1.53it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.822132:  14%|8     | 1/7 [00:01<00:03,  1.53it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.822132:  29%|#7    | 2/7 [00:01<00:03,  1.47it/s]\u001b[A[I 2024-02-06 20:35:37,861] Trial 1 finished with value: 0.8221324983878934 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.8221324983878934.\n",
      "\n",
      "feature_fraction, val_score: 0.822132:  29%|#7    | 2/7 [00:01<00:03,  1.47it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.822132:  29%|#7    | 2/7 [00:01<00:03,  1.47it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.822132:  43%|##5   | 3/7 [00:01<00:02,  1.51it/s]\u001b[A[I 2024-02-06 20:35:38,507] Trial 2 finished with value: 0.8229859460026321 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.8221324983878934.\n",
      "\n",
      "feature_fraction, val_score: 0.822132:  43%|##5   | 3/7 [00:01<00:02,  1.51it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.822132:  43%|##5   | 3/7 [00:02<00:02,  1.51it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.822132:  57%|###4  | 4/7 [00:02<00:02,  1.47it/s]\u001b[A[I 2024-02-06 20:35:39,212] Trial 3 finished with value: 0.8229203959244497 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.8221324983878934.\n",
      "\n",
      "feature_fraction, val_score: 0.822132:  57%|###4  | 4/7 [00:02<00:02,  1.47it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.822132:  57%|###4  | 4/7 [00:03<00:02,  1.47it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.822132:  71%|####2 | 5/7 [00:03<00:01,  1.54it/s]\u001b[A[I 2024-02-06 20:35:39,808] Trial 4 finished with value: 0.8273930413218842 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.8221324983878934.\n",
      "\n",
      "feature_fraction, val_score: 0.822132:  71%|####2 | 5/7 [00:03<00:01,  1.54it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.822132:  71%|####2 | 5/7 [00:04<00:01,  1.54it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.822132:  86%|#####1| 6/7 [00:04<00:00,  1.47it/s]\u001b[A[I 2024-02-06 20:35:40,549] Trial 5 finished with value: 0.8223921652367705 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.8221324983878934.\n",
      "\n",
      "feature_fraction, val_score: 0.822132:  86%|#####1| 6/7 [00:04<00:00,  1.47it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.821993:  86%|#####1| 6/7 [00:04<00:00,  1.47it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.821993: 100%|######| 7/7 [00:04<00:00,  1.44it/s]\u001b[A[I 2024-02-06 20:35:41,276] Trial 6 finished with value: 0.8219927159580277 and parameters: {'feature_fraction': 0.8}. Best is trial 6 with value: 0.8219927159580277.\n",
      "feature_fraction, val_score: 0.821993: 100%|######| 7/7 [00:04<00:00,  1.47it/s]\n",
      "\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "num_leaves, val_score: 0.821993:   0%|                   | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "num_leaves, val_score: 0.770612:   0%|                   | 0/20 [00:01<?, ?it/s]\u001b[A\n",
      "num_leaves, val_score: 0.770612:   5%|5          | 1/20 [00:01<00:27,  1.43s/it]\u001b[A[I 2024-02-06 20:35:42,714] Trial 7 finished with value: 0.7706121341253658 and parameters: {'num_leaves': 119}. Best is trial 7 with value: 0.7706121341253658.\n",
      "\n",
      "num_leaves, val_score: 0.770612:   5%|5          | 1/20 [00:01<00:27,  1.43s/it]\u001b[A\n",
      "num_leaves, val_score: 0.765352:   5%|5          | 1/20 [00:02<00:27,  1.43s/it]\u001b[A\n",
      "num_leaves, val_score: 0.765352:  10%|#1         | 2/20 [00:02<00:26,  1.46s/it]\u001b[A[I 2024-02-06 20:35:44,199] Trial 8 finished with value: 0.765352438619176 and parameters: {'num_leaves': 129}. Best is trial 8 with value: 0.765352438619176.\n",
      "\n",
      "num_leaves, val_score: 0.765352:  10%|#1         | 2/20 [00:02<00:26,  1.46s/it]\u001b[A\n",
      "num_leaves, val_score: 0.749415:  10%|#1         | 2/20 [00:05<00:26,  1.46s/it]\u001b[A\n",
      "num_leaves, val_score: 0.749415:  15%|#6         | 3/20 [00:05<00:31,  1.83s/it]\u001b[A[I 2024-02-06 20:35:46,462] Trial 9 finished with value: 0.7494146856657095 and parameters: {'num_leaves': 252}. Best is trial 9 with value: 0.7494146856657095.\n",
      "\n",
      "num_leaves, val_score: 0.749415:  15%|#6         | 3/20 [00:05<00:31,  1.83s/it]\u001b[A\n",
      "num_leaves, val_score: 0.749415:  15%|#6         | 3/20 [00:07<00:31,  1.83s/it]\u001b[A\n",
      "num_leaves, val_score: 0.749415:  20%|##2        | 4/20 [00:07<00:31,  1.99s/it]\u001b[A[I 2024-02-06 20:35:48,708] Trial 10 finished with value: 0.7501346490781587 and parameters: {'num_leaves': 248}. Best is trial 9 with value: 0.7494146856657095.\n",
      "\n",
      "num_leaves, val_score: 0.749415:  20%|##2        | 4/20 [00:07<00:31,  1.99s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  20%|##2        | 4/20 [00:09<00:31,  1.99s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  25%|##7        | 5/20 [00:09<00:31,  2.09s/it]\u001b[A[I 2024-02-06 20:35:50,959] Trial 11 finished with value: 0.7480816192606934 and parameters: {'num_leaves': 249}. Best is trial 11 with value: 0.7480816192606934.\n",
      "\n",
      "num_leaves, val_score: 0.748082:  25%|##7        | 5/20 [00:09<00:31,  2.09s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  25%|##7        | 5/20 [00:11<00:31,  2.09s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  30%|###3       | 6/20 [00:11<00:30,  2.15s/it]\u001b[A[I 2024-02-06 20:35:53,242] Trial 12 finished with value: 0.7512162699218284 and parameters: {'num_leaves': 255}. Best is trial 11 with value: 0.7480816192606934.\n",
      "\n",
      "num_leaves, val_score: 0.748082:  30%|###3       | 6/20 [00:11<00:30,  2.15s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  30%|###3       | 6/20 [00:13<00:30,  2.15s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  35%|###8       | 7/20 [00:13<00:27,  2.10s/it]\u001b[A[I 2024-02-06 20:35:55,234] Trial 13 finished with value: 0.754750464874871 and parameters: {'num_leaves': 208}. Best is trial 11 with value: 0.7480816192606934.\n",
      "\n",
      "num_leaves, val_score: 0.748082:  35%|###8       | 7/20 [00:13<00:27,  2.10s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  35%|###8       | 7/20 [00:14<00:27,  2.10s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  40%|####4      | 8/20 [00:14<00:18,  1.51s/it]\u001b[A[I 2024-02-06 20:35:55,466] Trial 14 finished with value: 0.8561082563364847 and parameters: {'num_leaves': 3}. Best is trial 11 with value: 0.7480816192606934.\n",
      "\n",
      "num_leaves, val_score: 0.748082:  40%|####4      | 8/20 [00:14<00:18,  1.51s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  40%|####4      | 8/20 [00:16<00:18,  1.51s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  45%|####9      | 9/20 [00:16<00:17,  1.62s/it]\u001b[A[I 2024-02-06 20:35:57,348] Trial 15 finished with value: 0.754234916339213 and parameters: {'num_leaves': 192}. Best is trial 11 with value: 0.7480816192606934.\n",
      "\n",
      "num_leaves, val_score: 0.748082:  45%|####9      | 9/20 [00:16<00:17,  1.62s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  45%|####9      | 9/20 [00:17<00:17,  1.62s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  50%|#####     | 10/20 [00:17<00:16,  1.69s/it]\u001b[A[I 2024-02-06 20:35:59,195] Trial 16 finished with value: 0.7559158790326179 and parameters: {'num_leaves': 187}. Best is trial 11 with value: 0.7480816192606934.\n",
      "\n",
      "num_leaves, val_score: 0.748082:  50%|#####     | 10/20 [00:17<00:16,  1.69s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  50%|#####     | 10/20 [00:18<00:16,  1.69s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  55%|#####5    | 11/20 [00:18<00:13,  1.50s/it]\u001b[A[I 2024-02-06 20:36:00,272] Trial 17 finished with value: 0.7935198562345605 and parameters: {'num_leaves': 71}. Best is trial 11 with value: 0.7480816192606934.\n",
      "\n",
      "num_leaves, val_score: 0.748082:  55%|#####5    | 11/20 [00:18<00:13,  1.50s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  55%|#####5    | 11/20 [00:21<00:13,  1.50s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  60%|######    | 12/20 [00:21<00:13,  1.66s/it]\u001b[A[I 2024-02-06 20:36:02,295] Trial 18 finished with value: 0.7522044135238491 and parameters: {'num_leaves': 215}. Best is trial 11 with value: 0.7480816192606934.\n",
      "\n",
      "num_leaves, val_score: 0.748082:  60%|######    | 12/20 [00:21<00:13,  1.66s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  60%|######    | 12/20 [00:22<00:13,  1.66s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  65%|######5   | 13/20 [00:22<00:11,  1.68s/it]\u001b[A[I 2024-02-06 20:36:04,018] Trial 19 finished with value: 0.757538106847666 and parameters: {'num_leaves': 166}. Best is trial 11 with value: 0.7480816192606934.\n",
      "\n",
      "num_leaves, val_score: 0.748082:  65%|######5   | 13/20 [00:22<00:11,  1.68s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  65%|######5   | 13/20 [00:24<00:11,  1.68s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  70%|#######   | 14/20 [00:24<00:11,  1.86s/it]\u001b[A[I 2024-02-06 20:36:06,278] Trial 20 finished with value: 0.7512162699218284 and parameters: {'num_leaves': 255}. Best is trial 11 with value: 0.7480816192606934.\n",
      "\n",
      "num_leaves, val_score: 0.748082:  70%|#######   | 14/20 [00:25<00:11,  1.86s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  70%|#######   | 14/20 [00:27<00:11,  1.86s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  75%|#######5  | 15/20 [00:27<00:09,  1.94s/it]\u001b[A[I 2024-02-06 20:36:08,421] Trial 21 finished with value: 0.7519835820939932 and parameters: {'num_leaves': 233}. Best is trial 11 with value: 0.7480816192606934.\n",
      "\n",
      "num_leaves, val_score: 0.748082:  75%|#######5  | 15/20 [00:27<00:09,  1.94s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  75%|#######5  | 15/20 [00:29<00:09,  1.94s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  80%|########  | 16/20 [00:29<00:08,  2.04s/it]\u001b[A[I 2024-02-06 20:36:10,680] Trial 22 finished with value: 0.7512162699218284 and parameters: {'num_leaves': 255}. Best is trial 11 with value: 0.7480816192606934.\n",
      "\n",
      "num_leaves, val_score: 0.748082:  80%|########  | 16/20 [00:29<00:08,  2.04s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  80%|########  | 16/20 [00:31<00:08,  2.04s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  85%|########5 | 17/20 [00:31<00:05,  1.93s/it]\u001b[A[I 2024-02-06 20:36:12,359] Trial 23 finished with value: 0.7593071190790983 and parameters: {'num_leaves': 160}. Best is trial 11 with value: 0.7480816192606934.\n",
      "\n",
      "num_leaves, val_score: 0.748082:  85%|########5 | 17/20 [00:31<00:05,  1.93s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  85%|########5 | 17/20 [00:33<00:05,  1.93s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  90%|######### | 18/20 [00:33<00:03,  1.97s/it]\u001b[A[I 2024-02-06 20:36:14,430] Trial 24 finished with value: 0.7544494705425244 and parameters: {'num_leaves': 221}. Best is trial 11 with value: 0.7480816192606934.\n",
      "\n",
      "num_leaves, val_score: 0.748082:  90%|######### | 18/20 [00:33<00:03,  1.97s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  90%|######### | 18/20 [00:35<00:03,  1.97s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  95%|#########5| 19/20 [00:35<00:02,  2.00s/it]\u001b[A[I 2024-02-06 20:36:16,503] Trial 25 finished with value: 0.7526799519878018 and parameters: {'num_leaves': 223}. Best is trial 11 with value: 0.7480816192606934.\n",
      "\n",
      "num_leaves, val_score: 0.748082:  95%|#########5| 19/20 [00:35<00:02,  2.00s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082:  95%|#########5| 19/20 [00:37<00:02,  2.00s/it]\u001b[A\n",
      "num_leaves, val_score: 0.748082: 100%|##########| 20/20 [00:37<00:00,  2.06s/it]\u001b[A[I 2024-02-06 20:36:18,684] Trial 26 finished with value: 0.7521499042023028 and parameters: {'num_leaves': 234}. Best is trial 11 with value: 0.7480816192606934.\n",
      "num_leaves, val_score: 0.748082: 100%|##########| 20/20 [00:37<00:00,  1.87s/it]\n",
      "\n",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "bagging, val_score: 0.748082:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "bagging, val_score: 0.748082:   0%|                      | 0/10 [00:02<?, ?it/s]\u001b[A\n",
      "bagging, val_score: 0.748082:  10%|#4            | 1/10 [00:02<00:24,  2.78s/it]\u001b[A[I 2024-02-06 20:36:21,463] Trial 27 finished with value: 0.7699082459227067 and parameters: {'bagging_fraction': 0.6600299834267866, 'bagging_freq': 4}. Best is trial 27 with value: 0.7699082459227067.\n",
      "\n",
      "bagging, val_score: 0.748082:  10%|#4            | 1/10 [00:02<00:24,  2.78s/it]\u001b[A\n",
      "bagging, val_score: 0.748082:  10%|#4            | 1/10 [00:05<00:24,  2.78s/it]\u001b[A\n",
      "bagging, val_score: 0.748082:  20%|##8           | 2/10 [00:05<00:19,  2.48s/it]\u001b[A[I 2024-02-06 20:36:23,743] Trial 28 finished with value: 0.7503512085954591 and parameters: {'bagging_fraction': 0.98961912426822, 'bagging_freq': 1}. Best is trial 28 with value: 0.7503512085954591.\n",
      "\n",
      "bagging, val_score: 0.748082:  20%|##8           | 2/10 [00:05<00:19,  2.48s/it]\u001b[A\n",
      "bagging, val_score: 0.748082:  20%|##8           | 2/10 [00:07<00:19,  2.48s/it]\u001b[A\n",
      "bagging, val_score: 0.748082:  30%|####2         | 3/10 [00:07<00:17,  2.55s/it]\u001b[A[I 2024-02-06 20:36:26,378] Trial 29 finished with value: 0.7974529172032094 and parameters: {'bagging_fraction': 0.4299851005074905, 'bagging_freq': 7}. Best is trial 28 with value: 0.7503512085954591.\n",
      "\n",
      "bagging, val_score: 0.748082:  30%|####2         | 3/10 [00:07<00:17,  2.55s/it]\u001b[A\n",
      "bagging, val_score: 0.748082:  30%|####2         | 3/10 [00:09<00:17,  2.55s/it]\u001b[A\n",
      "bagging, val_score: 0.748082:  40%|#####6        | 4/10 [00:09<00:14,  2.45s/it]\u001b[A[I 2024-02-06 20:36:28,659] Trial 30 finished with value: 0.7489887242415281 and parameters: {'bagging_fraction': 0.99672548094224, 'bagging_freq': 1}. Best is trial 30 with value: 0.7489887242415281.\n",
      "\n",
      "bagging, val_score: 0.748082:  40%|#####6        | 4/10 [00:09<00:14,  2.45s/it]\u001b[A\n",
      "bagging, val_score: 0.748082:  40%|#####6        | 4/10 [00:12<00:14,  2.45s/it]\u001b[A\n",
      "bagging, val_score: 0.748082:  50%|#######       | 5/10 [00:12<00:11,  2.39s/it]\u001b[A[I 2024-02-06 20:36:30,951] Trial 31 finished with value: 0.7495748823158269 and parameters: {'bagging_fraction': 0.9961155055251214, 'bagging_freq': 1}. Best is trial 30 with value: 0.7489887242415281.\n",
      "\n",
      "bagging, val_score: 0.748082:  50%|#######       | 5/10 [00:12<00:11,  2.39s/it]\u001b[A\n",
      "bagging, val_score: 0.748082:  50%|#######       | 5/10 [00:14<00:11,  2.39s/it]\u001b[A\n",
      "bagging, val_score: 0.748082:  60%|########4     | 6/10 [00:14<00:09,  2.36s/it]\u001b[A[I 2024-02-06 20:36:33,264] Trial 32 finished with value: 0.7506220229051109 and parameters: {'bagging_fraction': 0.9802981813455509, 'bagging_freq': 1}. Best is trial 30 with value: 0.7489887242415281.\n",
      "\n",
      "bagging, val_score: 0.748082:  60%|########4     | 6/10 [00:14<00:09,  2.36s/it]\u001b[A\n",
      "bagging, val_score: 0.748082:  60%|########4     | 6/10 [00:17<00:09,  2.36s/it]\u001b[A\n",
      "bagging, val_score: 0.748082:  70%|#########7    | 7/10 [00:17<00:07,  2.53s/it]\u001b[A[I 2024-02-06 20:36:36,127] Trial 33 finished with value: 0.7565864913152074 and parameters: {'bagging_fraction': 0.849873159011444, 'bagging_freq': 2}. Best is trial 30 with value: 0.7489887242415281.\n",
      "\n",
      "bagging, val_score: 0.748082:  70%|#########7    | 7/10 [00:17<00:07,  2.53s/it]\u001b[A\n",
      "bagging, val_score: 0.748082:  70%|#########7    | 7/10 [00:20<00:07,  2.53s/it]\u001b[A\n",
      "bagging, val_score: 0.748082:  80%|###########2  | 8/10 [00:20<00:05,  2.59s/it]\u001b[A[I 2024-02-06 20:36:38,844] Trial 34 finished with value: 0.7619770461552287 and parameters: {'bagging_fraction': 0.7995852772776697, 'bagging_freq': 3}. Best is trial 30 with value: 0.7489887242415281.\n",
      "\n",
      "bagging, val_score: 0.748082:  80%|###########2  | 8/10 [00:20<00:05,  2.59s/it]\u001b[A\n",
      "bagging, val_score: 0.748082:  80%|###########2  | 8/10 [00:22<00:05,  2.59s/it]\u001b[A\n",
      "bagging, val_score: 0.748082:  90%|############6 | 9/10 [00:22<00:02,  2.66s/it]\u001b[A[I 2024-02-06 20:36:41,677] Trial 35 finished with value: 0.7515721340939044 and parameters: {'bagging_fraction': 0.9917264437028052, 'bagging_freq': 6}. Best is trial 30 with value: 0.7489887242415281.\n",
      "\n",
      "bagging, val_score: 0.748082:  90%|############6 | 9/10 [00:22<00:02,  2.66s/it]\u001b[A\n",
      "bagging, val_score: 0.748082:  90%|############6 | 9/10 [00:25<00:02,  2.66s/it]\u001b[A\n",
      "bagging, val_score: 0.748082: 100%|#############| 10/10 [00:25<00:00,  2.56s/it]\u001b[A[I 2024-02-06 20:36:44,012] Trial 36 finished with value: 0.7577065052068114 and parameters: {'bagging_fraction': 0.8244413641837602, 'bagging_freq': 1}. Best is trial 30 with value: 0.7489887242415281.\n",
      "bagging, val_score: 0.748082: 100%|#############| 10/10 [00:25<00:00,  2.53s/it]\n",
      "\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.748082:   0%|       | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.748082:   0%|       | 0/6 [00:02<?, ?it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.748082:  17%|1| 1/6 [00:02<00:11,  2.23s/i\u001b[A[I 2024-02-06 20:36:46,245] Trial 37 finished with value: 0.7480816192606934 and parameters: {'feature_fraction': 0.784}. Best is trial 37 with value: 0.7480816192606934.\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.748082:  17%|1| 1/6 [00:02<00:11,  2.23s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.748082:  17%|1| 1/6 [00:04<00:11,  2.23s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.748082:  33%|3| 2/6 [00:04<00:08,  2.23s/i\u001b[A[I 2024-02-06 20:36:48,475] Trial 38 finished with value: 0.7480816192606934 and parameters: {'feature_fraction': 0.8160000000000001}. Best is trial 37 with value: 0.7480816192606934.\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.748082:  33%|3| 2/6 [00:04<00:08,  2.23s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.748082:  33%|3| 2/6 [00:06<00:08,  2.23s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.748082:  50%|5| 3/6 [00:06<00:06,  2.19s/i\u001b[A[I 2024-02-06 20:36:50,627] Trial 39 finished with value: 0.749527766234489 and parameters: {'feature_fraction': 0.7520000000000001}. Best is trial 37 with value: 0.7480816192606934.\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.748082:  50%|5| 3/6 [00:06<00:06,  2.19s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.748082:  50%|5| 3/6 [00:08<00:06,  2.19s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.748082:  67%|6| 4/6 [00:08<00:04,  2.24s/i\u001b[A[I 2024-02-06 20:36:52,935] Trial 40 finished with value: 0.7530980130136457 and parameters: {'feature_fraction': 0.88}. Best is trial 37 with value: 0.7480816192606934.\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.748082:  67%|6| 4/6 [00:08<00:04,  2.24s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.748082:  67%|6| 4/6 [00:11<00:04,  2.24s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.748082:  83%|8| 5/6 [00:11<00:02,  2.21s/i\u001b[A[I 2024-02-06 20:36:55,081] Trial 41 finished with value: 0.749527766234489 and parameters: {'feature_fraction': 0.7200000000000001}. Best is trial 37 with value: 0.7480816192606934.\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.748082:  83%|8| 5/6 [00:11<00:02,  2.21s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.748082:  83%|8| 5/6 [00:13<00:02,  2.21s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.748082: 100%|#| 6/6 [00:13<00:00,  2.24s/i\u001b[A[I 2024-02-06 20:36:57,382] Trial 42 finished with value: 0.7530980130136457 and parameters: {'feature_fraction': 0.8480000000000001}. Best is trial 37 with value: 0.7480816192606934.\n",
      "feature_fraction_stage2, val_score: 0.748082: 100%|#| 6/6 [00:13<00:00,  2.23s/i\n",
      "\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.748082:   0%|       | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.748082:   0%|       | 0/20 [00:02<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.748082:   5%| | 1/20 [00:02<00:45,  2.42s/i\u001b[A[I 2024-02-06 20:36:59,803] Trial 43 finished with value: 0.7480816130415379 and parameters: {'lambda_l1': 1.3577695517828251e-05, 'lambda_l2': 1.3246668179330415e-06}. Best is trial 43 with value: 0.7480816130415379.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:   5%| | 1/20 [00:02<00:45,  2.42s/i\u001b[A\n",
      "regularization_factors, val_score: 0.748082:   5%| | 1/20 [00:04<00:45,  2.42s/i\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  10%|1| 2/20 [00:04<00:43,  2.39s/i\u001b[A[I 2024-02-06 20:37:02,180] Trial 44 finished with value: 0.7480816152018896 and parameters: {'lambda_l1': 1.0330104076573561e-05, 'lambda_l2': 4.4846356808083924e-07}. Best is trial 43 with value: 0.7480816130415379.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:  10%|1| 2/20 [00:04<00:43,  2.39s/i\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  10%|1| 2/20 [00:07<00:43,  2.39s/i\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  15%|1| 3/20 [00:07<00:40,  2.37s/i\u001b[A[I 2024-02-06 20:37:04,530] Trial 45 finished with value: 0.748081616501656 and parameters: {'lambda_l1': 6.465886089196305e-06, 'lambda_l2': 4.898972374324921e-07}. Best is trial 43 with value: 0.7480816130415379.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:  15%|1| 3/20 [00:07<00:40,  2.37s/i\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  15%|1| 3/20 [00:09<00:40,  2.37s/i\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  20%|2| 4/20 [00:09<00:37,  2.36s/i\u001b[A[I 2024-02-06 20:37:06,871] Trial 46 finished with value: 0.7480816157167982 and parameters: {'lambda_l1': 9.00418694798466e-06, 'lambda_l2': 4.135732719103586e-07}. Best is trial 43 with value: 0.7480816130415379.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:  20%|2| 4/20 [00:09<00:37,  2.36s/i\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  20%|2| 4/20 [00:11<00:37,  2.36s/i\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  25%|2| 5/20 [00:11<00:35,  2.35s/i\u001b[A[I 2024-02-06 20:37:09,203] Trial 47 finished with value: 0.748081616296047 and parameters: {'lambda_l1': 7.721606564250461e-06, 'lambda_l2': 3.112217288250035e-07}. Best is trial 43 with value: 0.7480816130415379.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:  25%|2| 5/20 [00:11<00:35,  2.35s/i\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  25%|2| 5/20 [00:14<00:35,  2.35s/i\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  30%|3| 6/20 [00:14<00:32,  2.34s/i\u001b[A[I 2024-02-06 20:37:11,532] Trial 48 finished with value: 0.7480816154562738 and parameters: {'lambda_l1': 1.0018448396797543e-05, 'lambda_l2': 3.37702274542278e-07}. Best is trial 43 with value: 0.7480816130415379.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:  30%|3| 6/20 [00:14<00:32,  2.34s/i\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  30%|3| 6/20 [00:16<00:32,  2.34s/i\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  35%|3| 7/20 [00:16<00:30,  2.34s/i\u001b[A[I 2024-02-06 20:37:13,875] Trial 49 finished with value: 0.7480816140713634 and parameters: {'lambda_l1': 1.4119102805683991e-05, 'lambda_l2': 3.0691163970998466e-07}. Best is trial 43 with value: 0.7480816130415379.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:  35%|3| 7/20 [00:16<00:30,  2.34s/i\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  35%|3| 7/20 [00:18<00:30,  2.34s/i\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  40%|4| 8/20 [00:18<00:28,  2.34s/i\u001b[A[I 2024-02-06 20:37:16,210] Trial 50 finished with value: 0.7480816152056929 and parameters: {'lambda_l1': 1.0440746605962985e-05, 'lambda_l2': 4.1552080319005196e-07}. Best is trial 43 with value: 0.7480816130415379.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:  40%|4| 8/20 [00:18<00:28,  2.34s/i\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  40%|4| 8/20 [00:21<00:28,  2.34s/i\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  45%|4| 9/20 [00:21<00:25,  2.35s/i\u001b[A[I 2024-02-06 20:37:18,568] Trial 51 finished with value: 0.7480816145702521 and parameters: {'lambda_l1': 1.258357915904455e-05, 'lambda_l2': 3.293571576255881e-07}. Best is trial 43 with value: 0.7480816130415379.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:  45%|4| 9/20 [00:21<00:25,  2.35s/i\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  45%|4| 9/20 [00:23<00:25,  2.35s/i\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  50%|5| 10/20 [00:23<00:23,  2.34s/\u001b[A[I 2024-02-06 20:37:20,911] Trial 52 finished with value: 0.7480816137171203 and parameters: {'lambda_l1': 1.5147519712303897e-05, 'lambda_l2': 3.1511017568235044e-07}. Best is trial 43 with value: 0.7480816130415379.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:  50%|5| 10/20 [00:23<00:23,  2.34s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  50%|5| 10/20 [00:25<00:23,  2.34s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  55%|5| 11/20 [00:25<00:21,  2.34s/\u001b[A[I 2024-02-06 20:37:23,252] Trial 53 finished with value: 0.748081611404678 and parameters: {'lambda_l1': 2.1815612773016404e-05, 'lambda_l2': 3.464961295139208e-07}. Best is trial 53 with value: 0.748081611404678.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:  55%|5| 11/20 [00:25<00:21,  2.34s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  55%|5| 11/20 [00:28<00:21,  2.34s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  60%|6| 12/20 [00:28<00:18,  2.34s/\u001b[A[I 2024-02-06 20:37:25,590] Trial 54 finished with value: 0.7480815991327935 and parameters: {'lambda_l1': 5.7873765278257146e-05, 'lambda_l2': 2.9806910147125455e-07}. Best is trial 54 with value: 0.7480815991327935.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:  60%|6| 12/20 [00:28<00:18,  2.34s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  60%|6| 12/20 [00:30<00:18,  2.34s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  65%|6| 13/20 [00:30<00:16,  2.34s/\u001b[A[I 2024-02-06 20:37:27,939] Trial 55 finished with value: 0.7514828349236654 and parameters: {'lambda_l1': 0.0009466758950847021, 'lambda_l2': 1.2250537144951266e-08}. Best is trial 54 with value: 0.7480815991327935.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:  65%|6| 13/20 [00:30<00:16,  2.34s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  65%|6| 13/20 [00:32<00:16,  2.34s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  70%|7| 14/20 [00:32<00:14,  2.35s/\u001b[A[I 2024-02-06 20:37:30,302] Trial 56 finished with value: 0.75052490234097 and parameters: {'lambda_l1': 0.00032821357055731797, 'lambda_l2': 0.0009183101520165827}. Best is trial 54 with value: 0.7480815991327935.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:  70%|7| 14/20 [00:32<00:14,  2.35s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  70%|7| 14/20 [00:35<00:14,  2.35s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  75%|7| 15/20 [00:35<00:11,  2.34s/\u001b[A[I 2024-02-06 20:37:32,629] Trial 57 finished with value: 0.7480816086051663 and parameters: {'lambda_l1': 2.9183663563308915e-08, 'lambda_l2': 8.93758991697283e-06}. Best is trial 54 with value: 0.7480815991327935.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:  75%|7| 15/20 [00:35<00:11,  2.34s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  75%|7| 15/20 [00:37<00:11,  2.34s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  80%|8| 16/20 [00:37<00:09,  2.34s/\u001b[A[I 2024-02-06 20:37:34,962] Trial 58 finished with value: 0.748081592818914 and parameters: {'lambda_l1': 1.1384075040552487e-07, 'lambda_l2': 2.2066110846125466e-05}. Best is trial 58 with value: 0.748081592818914.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:  80%|8| 16/20 [00:37<00:09,  2.34s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  80%|8| 16/20 [00:39<00:09,  2.34s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  85%|8| 17/20 [00:39<00:07,  2.34s/\u001b[A[I 2024-02-06 20:37:37,304] Trial 59 finished with value: 0.7480815828943486 and parameters: {'lambda_l1': 1.3290664069932643e-08, 'lambda_l2': 3.046552958587637e-05}. Best is trial 59 with value: 0.7480815828943486.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:  85%|8| 17/20 [00:39<00:07,  2.34s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  85%|8| 17/20 [00:42<00:07,  2.34s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  90%|9| 18/20 [00:42<00:04,  2.34s/\u001b[A[I 2024-02-06 20:37:39,640] Trial 60 finished with value: 0.7480815820542208 and parameters: {'lambda_l1': 1.0261527828371123e-08, 'lambda_l2': 3.118420685714272e-05}. Best is trial 60 with value: 0.7480815820542208.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:  90%|9| 18/20 [00:42<00:04,  2.34s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  90%|9| 18/20 [00:44<00:04,  2.34s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  95%|9| 19/20 [00:44<00:02,  2.34s/\u001b[A[I 2024-02-06 20:37:41,978] Trial 61 finished with value: 0.7480815754748888 and parameters: {'lambda_l1': 1.145725502355992e-08, 'lambda_l2': 3.665541143794617e-05}. Best is trial 61 with value: 0.7480815754748888.\n",
      "\n",
      "regularization_factors, val_score: 0.748082:  95%|9| 19/20 [00:44<00:02,  2.34s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082:  95%|9| 19/20 [00:46<00:02,  2.34s/\u001b[A\n",
      "regularization_factors, val_score: 0.748082: 100%|#| 20/20 [00:46<00:00,  2.34s/\u001b[A[I 2024-02-06 20:37:44,314] Trial 62 finished with value: 0.7480815646798713 and parameters: {'lambda_l1': 1.1356180873291287e-08, 'lambda_l2': 4.569030487741186e-05}. Best is trial 62 with value: 0.7480815646798713.\n",
      "regularization_factors, val_score: 0.748082: 100%|#| 20/20 [00:46<00:00,  2.35s/\n",
      "\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "min_child_samples, val_score: 0.748082:   0%|             | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "min_child_samples, val_score: 0.748082:   0%|             | 0/5 [00:01<?, ?it/s]\u001b[A\n",
      "min_child_samples, val_score: 0.748082:  20%|#    | 1/5 [00:01<00:06,  1.66s/it]\u001b[A[I 2024-02-06 20:37:45,978] Trial 63 finished with value: 0.8030375914469502 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.8030375914469502.\n",
      "\n",
      "min_child_samples, val_score: 0.748082:  20%|#    | 1/5 [00:01<00:06,  1.66s/it]\u001b[A\n",
      "min_child_samples, val_score: 0.748082:  20%|#    | 1/5 [00:04<00:06,  1.66s/it]\u001b[A\n",
      "min_child_samples, val_score: 0.748082:  40%|##   | 2/5 [00:04<00:06,  2.08s/it]\u001b[A[I 2024-02-06 20:37:48,350] Trial 64 finished with value: 0.758157602202646 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 0.758157602202646.\n",
      "\n",
      "min_child_samples, val_score: 0.748082:  40%|##   | 2/5 [00:04<00:06,  2.08s/it]\u001b[A\n",
      "min_child_samples, val_score: 0.743962:  40%|##   | 2/5 [00:06<00:06,  2.08s/it]\u001b[A\n",
      "min_child_samples, val_score: 0.743962:  60%|###  | 3/5 [00:06<00:04,  2.19s/it]\u001b[A[I 2024-02-06 20:37:50,674] Trial 65 finished with value: 0.7439624703966502 and parameters: {'min_child_samples': 5}. Best is trial 65 with value: 0.7439624703966502.\n",
      "\n",
      "min_child_samples, val_score: 0.743962:  60%|###  | 3/5 [00:06<00:04,  2.19s/it]\u001b[A\n",
      "min_child_samples, val_score: 0.743962:  60%|###  | 3/5 [00:08<00:04,  2.19s/it]\u001b[A\n",
      "min_child_samples, val_score: 0.743962:  80%|#### | 4/5 [00:08<00:02,  2.25s/it]\u001b[A[I 2024-02-06 20:37:53,024] Trial 66 finished with value: 0.7823624769462577 and parameters: {'min_child_samples': 50}. Best is trial 65 with value: 0.7439624703966502.\n",
      "\n",
      "min_child_samples, val_score: 0.743962:  80%|#### | 4/5 [00:08<00:02,  2.25s/it]\u001b[A\n",
      "min_child_samples, val_score: 0.741251:  80%|#### | 4/5 [00:11<00:02,  2.25s/it]\u001b[A\n",
      "min_child_samples, val_score: 0.741251: 100%|#####| 5/5 [00:11<00:00,  2.27s/it]\u001b[A[I 2024-02-06 20:37:55,333] Trial 67 finished with value: 0.7412511672150858 and parameters: {'min_child_samples': 10}. Best is trial 67 with value: 0.7412511672150858.\n",
      "min_child_samples, val_score: 0.741251: 100%|#####| 5/5 [00:11<00:00,  2.20s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "gbt_data = train_series.merge(forecast, on='ds', how='left')\n",
    "train_gbt, val_gbt = train_test_split(gbt_data, test_size=0.15, random_state=42)\n",
    "\n",
    "lgbm_te = OptunaLGBMRegressor(n_estimators=300, learning_rate=0.01, metric='mape', seed=42)\n",
    "\n",
    "lgbm_te.fit(\n",
    "    train_gbt.drop(['ds', 'y'], axis=1), \n",
    "    train_gbt.y.values,\n",
    "    val_gbt.drop(['ds', 'y'], axis=1),\n",
    "    val_gbt.y.values\n",
    ")\n",
    "\n",
    "test_gbt = new_test_series.merge(forecast, on='ds', how='left')\n",
    "preds = lgbm_te.predict(test_gbt.drop(['ds'], axis=1)) # preds = lgbm.predict(test_gbt.drop(['ds', 'y'], axis=1))\n",
    "\n",
    "forecast_df = test_gbt[['ds']].copy() # forecast_df = test_gbt[['ds', 'y', 'yhat']].copy()\n",
    "forecast_df['gbt_yhat'] = preds\n",
    "\n",
    "# forecast_df['gbt_yhat'] - предикт модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'model_te.h5py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/andreyboriskin/PycharmProjects/predprof/models/model_te/' + filename, 'wb') as file:\n",
    "\tpickle.dump(lgbm_te, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/andreyboriskin/PycharmProjects/predprof/models/' + filename ,'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.2584451 , -1.37954306, -1.22268945, -2.03356601, -1.26723486,\n",
       "       -2.82087916, -2.62727146])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(test_gbt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Осадки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_os = df.copy()\n",
    "df_os = df_os.rename(columns={'Сумма осадков': 'y'})\n",
    "df_os.drop(df_os.loc[df_os['y'] == '      '].index, inplace=True)\n",
    "df_os['y'] = df_os['y'].astype('float64')\n",
    "data = pd.DataFrame(columns=['ds', 'y'])\n",
    "data['ds'] = df_os.date\n",
    "data['y'] = df_os.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series = data # [data.ds < (data.ds.max() - timedelta(days=30))]\n",
    "# test_series = data[data.ds >= (data.ds.max() - timedelta(days=30))].drop(['y'], axis=1)\n",
    "start_date = '2022-12-31'\n",
    "end_date = '2023-01-07'\n",
    "\n",
    "start = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "end = datetime.strptime(end_date, '%Y-%m-%d')   \n",
    "\n",
    "daterange = [(start + timedelta(days=x)).strftime('%Y-%m-%d') for x in range(0, (end-start).days)]\n",
    "new_test_series = pd.DataFrame(pd.to_datetime(daterange), columns=['ds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:37:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:37:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "fb_os = prophet.Prophet()\n",
    "\n",
    "with suppress_stdout_stderr():\n",
    "    fb_os.fit(train_series)\n",
    "\n",
    "predictions = fb_os.make_future_dataframe(periods=len(new_test_series), freq='D')\n",
    "forecast = fb_os.predict(predictions)\n",
    "\n",
    "# v_fb_df = test_series.copy()\n",
    "# v_fb_df = v_fb_df.merge(forecast[['ds', 'yhat']], on='ds', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'fb_model_os.h5py'\n",
    "with open('/Users/andreyboriskin/PycharmProjects/predprof/models/model_os/' + filename, 'wb') as file:\n",
    "\tpickle.dump(fb_os, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-06 20:38:00,763] A new study created in memory with name: no-name-cf8b3281-0246-4300-aeef-798fbfb14282\n",
      "\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction, val_score: inf:   0%|                   | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.470755:   0%|              | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.470755:  14%|8     | 1/7 [00:00<00:02,  2.05it/s]\u001b[A[I 2024-02-06 20:38:01,255] Trial 0 finished with value: 0.4707550201916411 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.4707550201916411.\n",
      "\n",
      "feature_fraction, val_score: 0.470755:  14%|8     | 1/7 [00:00<00:02,  2.05it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.470755:  14%|8     | 1/7 [00:00<00:02,  2.05it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.470755:  29%|#7    | 2/7 [00:00<00:02,  2.10it/s]\u001b[A[I 2024-02-06 20:38:01,722] Trial 1 finished with value: 0.4719807070947092 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.4707550201916411.\n",
      "\n",
      "feature_fraction, val_score: 0.470755:  29%|#7    | 2/7 [00:00<00:02,  2.10it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.470755:  29%|#7    | 2/7 [00:01<00:02,  2.10it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.470755:  43%|##5   | 3/7 [00:01<00:01,  2.20it/s]\u001b[A[I 2024-02-06 20:38:02,151] Trial 2 finished with value: 0.4722868173576484 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.4707550201916411.\n",
      "\n",
      "feature_fraction, val_score: 0.470755:  43%|##5   | 3/7 [00:01<00:01,  2.20it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.470755:  43%|##5   | 3/7 [00:01<00:01,  2.20it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.470755:  57%|###4  | 4/7 [00:01<00:01,  2.31it/s]\u001b[A[I 2024-02-06 20:38:02,552] Trial 3 finished with value: 0.4711630037325936 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.4707550201916411.\n",
      "\n",
      "feature_fraction, val_score: 0.470755:  57%|###4  | 4/7 [00:01<00:01,  2.31it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.470540:  57%|###4  | 4/7 [00:02<00:01,  2.31it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.470540:  71%|####2 | 5/7 [00:02<00:00,  2.31it/s]\u001b[A[I 2024-02-06 20:38:02,982] Trial 4 finished with value: 0.4705398996569103 and parameters: {'feature_fraction': 0.5}. Best is trial 4 with value: 0.4705398996569103.\n",
      "\n",
      "feature_fraction, val_score: 0.470540:  71%|####2 | 5/7 [00:02<00:00,  2.31it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.470540:  71%|####2 | 5/7 [00:02<00:00,  2.31it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.470540:  86%|#####1| 6/7 [00:02<00:00,  2.22it/s]\u001b[A[I 2024-02-06 20:38:03,466] Trial 5 finished with value: 0.47198537333184565 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 4 with value: 0.4705398996569103.\n",
      "\n",
      "feature_fraction, val_score: 0.470540:  86%|#####1| 6/7 [00:02<00:00,  2.22it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.470540:  86%|#####1| 6/7 [00:03<00:00,  2.22it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.470540: 100%|######| 7/7 [00:03<00:00,  2.21it/s]\u001b[A[I 2024-02-06 20:38:03,927] Trial 6 finished with value: 0.47225373292438755 and parameters: {'feature_fraction': 0.7}. Best is trial 4 with value: 0.4705398996569103.\n",
      "feature_fraction, val_score: 0.470540: 100%|######| 7/7 [00:03<00:00,  2.21it/s]\n",
      "\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "num_leaves, val_score: 0.470540:   0%|                   | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "num_leaves, val_score: 0.470540:   0%|                   | 0/20 [00:01<?, ?it/s]\u001b[A\n",
      "num_leaves, val_score: 0.470540:   5%|5          | 1/20 [00:01<00:30,  1.59s/it]\u001b[A[I 2024-02-06 20:38:05,515] Trial 7 finished with value: 0.47528963016241665 and parameters: {'num_leaves': 196}. Best is trial 7 with value: 0.47528963016241665.\n",
      "\n",
      "num_leaves, val_score: 0.470540:   5%|5          | 1/20 [00:01<00:30,  1.59s/it]\u001b[A\n",
      "num_leaves, val_score: 0.468136:   5%|5          | 1/20 [00:01<00:30,  1.59s/it]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  10%|#1         | 2/20 [00:01<00:14,  1.26it/s]\u001b[A[I 2024-02-06 20:38:05,756] Trial 8 finished with value: 0.4681362997242196 and parameters: {'num_leaves': 8}. Best is trial 8 with value: 0.4681362997242196.\n",
      "\n",
      "num_leaves, val_score: 0.468136:  10%|#1         | 2/20 [00:01<00:14,  1.26it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  10%|#1         | 2/20 [00:02<00:14,  1.26it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  15%|#6         | 3/20 [00:02<00:09,  1.78it/s]\u001b[A[I 2024-02-06 20:38:06,041] Trial 9 finished with value: 0.46938974364777103 and parameters: {'num_leaves': 12}. Best is trial 8 with value: 0.4681362997242196.\n",
      "\n",
      "num_leaves, val_score: 0.468136:  15%|#6         | 3/20 [00:02<00:09,  1.78it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  15%|#6         | 3/20 [00:02<00:09,  1.78it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  20%|##2        | 4/20 [00:02<00:06,  2.29it/s]\u001b[A[I 2024-02-06 20:38:06,285] Trial 10 finished with value: 0.4681362997242196 and parameters: {'num_leaves': 8}. Best is trial 8 with value: 0.4681362997242196.\n",
      "\n",
      "num_leaves, val_score: 0.468136:  20%|##2        | 4/20 [00:02<00:06,  2.29it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  20%|##2        | 4/20 [00:02<00:06,  2.29it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  25%|##7        | 5/20 [00:02<00:05,  2.65it/s]\u001b[A[I 2024-02-06 20:38:06,560] Trial 11 finished with value: 0.46872380431519794 and parameters: {'num_leaves': 11}. Best is trial 8 with value: 0.4681362997242196.\n",
      "\n",
      "num_leaves, val_score: 0.468136:  25%|##7        | 5/20 [00:02<00:05,  2.65it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  25%|##7        | 5/20 [00:03<00:05,  2.65it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  30%|###3       | 6/20 [00:03<00:07,  2.00it/s]\u001b[A[I 2024-02-06 20:38:07,299] Trial 12 finished with value: 0.4723965734671962 and parameters: {'num_leaves': 73}. Best is trial 8 with value: 0.4681362997242196.\n",
      "\n",
      "num_leaves, val_score: 0.468136:  30%|###3       | 6/20 [00:03<00:07,  2.00it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  30%|###3       | 6/20 [00:04<00:07,  2.00it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  35%|###8       | 7/20 [00:04<00:08,  1.55it/s]\u001b[A[I 2024-02-06 20:38:08,245] Trial 13 finished with value: 0.4711889026556459 and parameters: {'num_leaves': 101}. Best is trial 8 with value: 0.4681362997242196.\n",
      "\n",
      "num_leaves, val_score: 0.468136:  35%|###8       | 7/20 [00:04<00:08,  1.55it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  35%|###8       | 7/20 [00:04<00:08,  1.55it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  40%|####4      | 8/20 [00:04<00:06,  1.93it/s]\u001b[A[I 2024-02-06 20:38:08,486] Trial 14 finished with value: 0.4681362997242196 and parameters: {'num_leaves': 8}. Best is trial 8 with value: 0.4681362997242196.\n",
      "\n",
      "num_leaves, val_score: 0.468136:  40%|####4      | 8/20 [00:04<00:06,  1.93it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  40%|####4      | 8/20 [00:06<00:06,  1.93it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  45%|####9      | 9/20 [00:06<00:08,  1.23it/s]\u001b[A[I 2024-02-06 20:38:09,955] Trial 15 finished with value: 0.477525846316515 and parameters: {'num_leaves': 179}. Best is trial 8 with value: 0.4681362997242196.\n",
      "\n",
      "num_leaves, val_score: 0.468136:  45%|####9      | 9/20 [00:06<00:08,  1.23it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  45%|####9      | 9/20 [00:06<00:08,  1.23it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  50%|#####     | 10/20 [00:06<00:07,  1.32it/s]\u001b[A[I 2024-02-06 20:38:10,590] Trial 16 finished with value: 0.47400397986973347 and parameters: {'num_leaves': 58}. Best is trial 8 with value: 0.4681362997242196.\n",
      "\n",
      "num_leaves, val_score: 0.468136:  50%|#####     | 10/20 [00:06<00:07,  1.32it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  50%|#####     | 10/20 [00:07<00:07,  1.32it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  55%|#####5    | 11/20 [00:07<00:08,  1.09it/s]\u001b[A[I 2024-02-06 20:38:11,857] Trial 17 finished with value: 0.4733460379519336 and parameters: {'num_leaves': 145}. Best is trial 8 with value: 0.4681362997242196.\n",
      "\n",
      "num_leaves, val_score: 0.468136:  55%|#####5    | 11/20 [00:07<00:08,  1.09it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  55%|#####5    | 11/20 [00:09<00:08,  1.09it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  60%|######    | 12/20 [00:09<00:09,  1.21s/it]\u001b[A[I 2024-02-06 20:38:13,739] Trial 18 finished with value: 0.4796473385206224 and parameters: {'num_leaves': 256}. Best is trial 8 with value: 0.4681362997242196.\n",
      "\n",
      "num_leaves, val_score: 0.468136:  60%|######    | 12/20 [00:09<00:09,  1.21s/it]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  60%|######    | 12/20 [00:10<00:09,  1.21s/it]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  65%|######5   | 13/20 [00:10<00:07,  1.03s/it]\u001b[A[I 2024-02-06 20:38:14,353] Trial 19 finished with value: 0.4717906047337061 and parameters: {'num_leaves': 54}. Best is trial 8 with value: 0.4681362997242196.\n",
      "\n",
      "num_leaves, val_score: 0.468136:  65%|######5   | 13/20 [00:10<00:07,  1.03s/it]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  65%|######5   | 13/20 [00:10<00:07,  1.03s/it]\u001b[A\n",
      "num_leaves, val_score: 0.468136:  70%|#######   | 14/20 [00:10<00:05,  1.12it/s]\u001b[A[I 2024-02-06 20:38:14,923] Trial 20 finished with value: 0.47146375531938534 and parameters: {'num_leaves': 49}. Best is trial 8 with value: 0.4681362997242196.\n",
      "\n",
      "num_leaves, val_score: 0.468136:  70%|#######   | 14/20 [00:10<00:05,  1.12it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468105:  70%|#######   | 14/20 [00:11<00:05,  1.12it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468105:  75%|#######5  | 15/20 [00:11<00:03,  1.47it/s]\u001b[A[I 2024-02-06 20:38:15,116] Trial 21 finished with value: 0.4681054785693271 and parameters: {'num_leaves': 4}. Best is trial 21 with value: 0.4681054785693271.\n",
      "\n",
      "num_leaves, val_score: 0.468105:  75%|#######5  | 15/20 [00:11<00:03,  1.47it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468105:  75%|#######5  | 15/20 [00:11<00:03,  1.47it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468105:  80%|########  | 16/20 [00:11<00:02,  1.88it/s]\u001b[A[I 2024-02-06 20:38:15,308] Trial 22 finished with value: 0.4681054785693271 and parameters: {'num_leaves': 4}. Best is trial 21 with value: 0.4681054785693271.\n",
      "\n",
      "num_leaves, val_score: 0.468105:  80%|########  | 16/20 [00:11<00:02,  1.88it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468105:  80%|########  | 16/20 [00:11<00:02,  1.88it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468105:  85%|########5 | 17/20 [00:11<00:01,  1.95it/s]\u001b[A[I 2024-02-06 20:38:15,776] Trial 23 finished with value: 0.47092485476654544 and parameters: {'num_leaves': 36}. Best is trial 21 with value: 0.4681054785693271.\n",
      "\n",
      "num_leaves, val_score: 0.468105:  85%|########5 | 17/20 [00:11<00:01,  1.95it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468105:  85%|########5 | 17/20 [00:12<00:01,  1.95it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468105:  90%|######### | 18/20 [00:12<00:01,  1.56it/s]\u001b[A[I 2024-02-06 20:38:16,709] Trial 24 finished with value: 0.47274092192310013 and parameters: {'num_leaves': 98}. Best is trial 21 with value: 0.4681054785693271.\n",
      "\n",
      "num_leaves, val_score: 0.468105:  90%|######### | 18/20 [00:12<00:01,  1.56it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468105:  90%|######### | 18/20 [00:13<00:01,  1.56it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468105:  95%|#########5| 19/20 [00:13<00:00,  1.72it/s]\u001b[A[I 2024-02-06 20:38:17,157] Trial 25 finished with value: 0.47014526583282207 and parameters: {'num_leaves': 32}. Best is trial 21 with value: 0.4681054785693271.\n",
      "\n",
      "num_leaves, val_score: 0.468105:  95%|#########5| 19/20 [00:13<00:00,  1.72it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468105:  95%|#########5| 19/20 [00:14<00:00,  1.72it/s]\u001b[A\n",
      "num_leaves, val_score: 0.468105: 100%|##########| 20/20 [00:14<00:00,  1.47it/s]\u001b[A[I 2024-02-06 20:38:18,058] Trial 26 finished with value: 0.471424161006379 and parameters: {'num_leaves': 95}. Best is trial 21 with value: 0.4681054785693271.\n",
      "num_leaves, val_score: 0.468105: 100%|##########| 20/20 [00:14<00:00,  1.42it/s]\n",
      "\n",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "bagging, val_score: 0.468105:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "bagging, val_score: 0.468105:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "bagging, val_score: 0.468105:  10%|#4            | 1/10 [00:00<00:02,  4.20it/s]\u001b[A[I 2024-02-06 20:38:18,299] Trial 27 finished with value: 0.46852203621861604 and parameters: {'bagging_fraction': 0.8664148472091322, 'bagging_freq': 4}. Best is trial 27 with value: 0.46852203621861604.\n",
      "\n",
      "bagging, val_score: 0.468105:  10%|#4            | 1/10 [00:00<00:02,  4.20it/s]\u001b[A\n",
      "bagging, val_score: 0.468105:  10%|#4            | 1/10 [00:00<00:02,  4.20it/s]\u001b[A\n",
      "bagging, val_score: 0.468105:  20%|##8           | 2/10 [00:00<00:01,  4.51it/s]\u001b[A[I 2024-02-06 20:38:18,509] Trial 28 finished with value: 0.4719661101857349 and parameters: {'bagging_fraction': 0.4321169860851269, 'bagging_freq': 1}. Best is trial 27 with value: 0.46852203621861604.\n",
      "\n",
      "bagging, val_score: 0.468105:  20%|##8           | 2/10 [00:00<00:01,  4.51it/s]\u001b[A\n",
      "bagging, val_score: 0.467729:  20%|##8           | 2/10 [00:00<00:01,  4.51it/s]\u001b[A\n",
      "bagging, val_score: 0.467729:  30%|####2         | 3/10 [00:00<00:01,  4.34it/s]\u001b[A[I 2024-02-06 20:38:18,750] Trial 29 finished with value: 0.4677287747990773 and parameters: {'bagging_fraction': 0.9751825449983549, 'bagging_freq': 7}. Best is trial 29 with value: 0.4677287747990773.\n",
      "\n",
      "bagging, val_score: 0.467729:  30%|####2         | 3/10 [00:00<00:01,  4.34it/s]\u001b[A\n",
      "bagging, val_score: 0.467703:  30%|####2         | 3/10 [00:00<00:01,  4.34it/s]\u001b[A\n",
      "bagging, val_score: 0.467703:  40%|#####6        | 4/10 [00:00<00:01,  4.28it/s]\u001b[A[I 2024-02-06 20:38:18,988] Trial 30 finished with value: 0.4677032483200091 and parameters: {'bagging_fraction': 0.9630886432237401, 'bagging_freq': 7}. Best is trial 30 with value: 0.4677032483200091.\n",
      "\n",
      "bagging, val_score: 0.467703:  40%|#####6        | 4/10 [00:00<00:01,  4.28it/s]\u001b[A\n",
      "bagging, val_score: 0.467703:  40%|#####6        | 4/10 [00:01<00:01,  4.28it/s]\u001b[A\n",
      "bagging, val_score: 0.467703:  50%|#######       | 5/10 [00:01<00:01,  4.22it/s]\u001b[A[I 2024-02-06 20:38:19,231] Trial 31 finished with value: 0.4681005606204627 and parameters: {'bagging_fraction': 0.9848289516466389, 'bagging_freq': 7}. Best is trial 30 with value: 0.4677032483200091.\n",
      "\n",
      "bagging, val_score: 0.467703:  50%|#######       | 5/10 [00:01<00:01,  4.22it/s]\u001b[A\n",
      "bagging, val_score: 0.467703:  50%|#######       | 5/10 [00:01<00:01,  4.22it/s]\u001b[A\n",
      "bagging, val_score: 0.467703:  60%|########4     | 6/10 [00:01<00:00,  4.19it/s]\u001b[A[I 2024-02-06 20:38:19,473] Trial 32 finished with value: 0.4682402652651486 and parameters: {'bagging_fraction': 0.9963530319463373, 'bagging_freq': 7}. Best is trial 30 with value: 0.4677032483200091.\n",
      "\n",
      "bagging, val_score: 0.467703:  60%|########4     | 6/10 [00:01<00:00,  4.19it/s]\u001b[A\n",
      "bagging, val_score: 0.467703:  60%|########4     | 6/10 [00:01<00:00,  4.19it/s]\u001b[A\n",
      "bagging, val_score: 0.467703:  70%|#########7    | 7/10 [00:01<00:00,  4.16it/s]\u001b[A[I 2024-02-06 20:38:19,717] Trial 33 finished with value: 0.46836383229400735 and parameters: {'bagging_fraction': 0.9970289352153223, 'bagging_freq': 7}. Best is trial 30 with value: 0.4677032483200091.\n",
      "\n",
      "bagging, val_score: 0.467703:  70%|#########7    | 7/10 [00:01<00:00,  4.16it/s]\u001b[A\n",
      "bagging, val_score: 0.467703:  70%|#########7    | 7/10 [00:01<00:00,  4.16it/s]\u001b[A\n",
      "bagging, val_score: 0.467703:  80%|###########2  | 8/10 [00:01<00:00,  4.19it/s]\u001b[A[I 2024-02-06 20:38:19,952] Trial 34 finished with value: 0.4684848612474047 and parameters: {'bagging_fraction': 0.8647558121606628, 'bagging_freq': 7}. Best is trial 30 with value: 0.4677032483200091.\n",
      "\n",
      "bagging, val_score: 0.467703:  80%|###########2  | 8/10 [00:01<00:00,  4.19it/s]\u001b[A\n",
      "bagging, val_score: 0.466628:  80%|###########2  | 8/10 [00:02<00:00,  4.19it/s]\u001b[A\n",
      "bagging, val_score: 0.466628:  90%|############6 | 9/10 [00:02<00:00,  4.18it/s]\u001b[A[I 2024-02-06 20:38:20,192] Trial 35 finished with value: 0.466628223399611 and parameters: {'bagging_fraction': 0.8918974992809516, 'bagging_freq': 5}. Best is trial 35 with value: 0.466628223399611.\n",
      "\n",
      "bagging, val_score: 0.466628:  90%|############6 | 9/10 [00:02<00:00,  4.18it/s]\u001b[A\n",
      "bagging, val_score: 0.466628:  90%|############6 | 9/10 [00:02<00:00,  4.18it/s]\u001b[A\n",
      "bagging, val_score: 0.466628: 100%|#############| 10/10 [00:02<00:00,  4.18it/s]\u001b[A[I 2024-02-06 20:38:20,431] Trial 36 finished with value: 0.4669270168108292 and parameters: {'bagging_fraction': 0.9454435691453458, 'bagging_freq': 5}. Best is trial 35 with value: 0.466628223399611.\n",
      "bagging, val_score: 0.466628: 100%|#############| 10/10 [00:02<00:00,  4.22it/s]\n",
      "\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.466628:   0%|       | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.466510:   0%|       | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.466510:  17%|1| 1/6 [00:00<00:01,  4.37it/\u001b[A[I 2024-02-06 20:38:20,662] Trial 37 finished with value: 0.4665104899401455 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 37 with value: 0.4665104899401455.\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.466510:  17%|1| 1/6 [00:00<00:01,  4.37it/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.466510:  17%|1| 1/6 [00:00<00:01,  4.37it/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.466510:  33%|3| 2/6 [00:00<00:00,  4.34it/\u001b[A[I 2024-02-06 20:38:20,894] Trial 38 finished with value: 0.466628223399611 and parameters: {'feature_fraction': 0.516}. Best is trial 37 with value: 0.4665104899401455.\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.466510:  33%|3| 2/6 [00:00<00:00,  4.34it/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.466510:  33%|3| 2/6 [00:00<00:00,  4.34it/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.466510:  50%|5| 3/6 [00:00<00:00,  4.40it/\u001b[A[I 2024-02-06 20:38:21,118] Trial 39 finished with value: 0.46654254403736106 and parameters: {'feature_fraction': 0.58}. Best is trial 37 with value: 0.4665104899401455.\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.466510:  50%|5| 3/6 [00:00<00:00,  4.40it/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.466510:  50%|5| 3/6 [00:00<00:00,  4.40it/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.466510:  67%|6| 4/6 [00:00<00:00,  4.38it/\u001b[A[I 2024-02-06 20:38:21,347] Trial 40 finished with value: 0.466628223399611 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 37 with value: 0.4665104899401455.\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.466510:  67%|6| 4/6 [00:00<00:00,  4.38it/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.466510:  67%|6| 4/6 [00:01<00:00,  4.38it/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.466510:  83%|8| 5/6 [00:01<00:00,  4.40it/\u001b[A[I 2024-02-06 20:38:21,573] Trial 41 finished with value: 0.4665104899401455 and parameters: {'feature_fraction': 0.484}. Best is trial 37 with value: 0.4665104899401455.\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.466510:  83%|8| 5/6 [00:01<00:00,  4.40it/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.466510:  83%|8| 5/6 [00:01<00:00,  4.40it/\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.466510: 100%|#| 6/6 [00:01<00:00,  4.42it/\u001b[A[I 2024-02-06 20:38:21,798] Trial 42 finished with value: 0.46658009079818596 and parameters: {'feature_fraction': 0.42}. Best is trial 37 with value: 0.4665104899401455.\n",
      "feature_fraction_stage2, val_score: 0.466510: 100%|#| 6/6 [00:01<00:00,  4.39it/\n",
      "\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.466510:   0%|       | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.466510:   0%|       | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.466510:   5%| | 1/20 [00:00<00:04,  4.27it/\u001b[A[I 2024-02-06 20:38:22,034] Trial 43 finished with value: 0.4665355677482116 and parameters: {'lambda_l1': 1.5729341043720892, 'lambda_l2': 2.701072808773922e-05}. Best is trial 43 with value: 0.4665355677482116.\n",
      "\n",
      "regularization_factors, val_score: 0.466510:   5%| | 1/20 [00:00<00:04,  4.27it/\u001b[A\n",
      "regularization_factors, val_score: 0.465787:   5%| | 1/20 [00:00<00:04,  4.27it/\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  10%|1| 2/20 [00:00<00:04,  4.24it/\u001b[A[I 2024-02-06 20:38:22,271] Trial 44 finished with value: 0.46578670092861435 and parameters: {'lambda_l1': 9.143307075764069, 'lambda_l2': 2.93065919281393e-05}. Best is trial 44 with value: 0.46578670092861435.\n",
      "\n",
      "regularization_factors, val_score: 0.465787:  10%|1| 2/20 [00:00<00:04,  4.24it/\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  10%|1| 2/20 [00:00<00:04,  4.24it/\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  15%|1| 3/20 [00:00<00:04,  4.23it/\u001b[A[I 2024-02-06 20:38:22,508] Trial 45 finished with value: 0.46596799411641787 and parameters: {'lambda_l1': 7.650679182698368, 'lambda_l2': 5.011190599663691e-05}. Best is trial 44 with value: 0.46578670092861435.\n",
      "\n",
      "regularization_factors, val_score: 0.465787:  15%|1| 3/20 [00:00<00:04,  4.23it/\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  15%|1| 3/20 [00:00<00:04,  4.23it/\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  20%|2| 4/20 [00:00<00:03,  4.34it/\u001b[A[I 2024-02-06 20:38:22,729] Trial 46 finished with value: 0.4660499268602933 and parameters: {'lambda_l1': 8.200524006000775, 'lambda_l2': 2.72292057190549e-05}. Best is trial 44 with value: 0.46578670092861435.\n",
      "\n",
      "regularization_factors, val_score: 0.465787:  20%|2| 4/20 [00:00<00:03,  4.34it/\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  20%|2| 4/20 [00:01<00:03,  4.34it/\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  25%|2| 5/20 [00:01<00:03,  4.31it/\u001b[A[I 2024-02-06 20:38:22,965] Trial 47 finished with value: 0.4659510017269937 and parameters: {'lambda_l1': 6.534137307418163, 'lambda_l2': 3.194690137475269e-05}. Best is trial 44 with value: 0.46578670092861435.\n",
      "\n",
      "regularization_factors, val_score: 0.465787:  25%|2| 5/20 [00:01<00:03,  4.31it/\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  25%|2| 5/20 [00:01<00:03,  4.31it/\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  30%|3| 6/20 [00:01<00:03,  4.25it/\u001b[A[I 2024-02-06 20:38:23,206] Trial 48 finished with value: 0.46588394885290774 and parameters: {'lambda_l1': 9.347788868658473, 'lambda_l2': 3.474719356765736e-05}. Best is trial 44 with value: 0.46578670092861435.\n",
      "\n",
      "regularization_factors, val_score: 0.465787:  30%|3| 6/20 [00:01<00:03,  4.25it/\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  30%|3| 6/20 [00:01<00:03,  4.25it/\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  35%|3| 7/20 [00:01<00:03,  4.23it/\u001b[A[I 2024-02-06 20:38:23,444] Trial 49 finished with value: 0.4658596667073328 and parameters: {'lambda_l1': 8.7749600741742, 'lambda_l2': 2.9069938418472557e-05}. Best is trial 44 with value: 0.46578670092861435.\n",
      "\n",
      "regularization_factors, val_score: 0.465787:  35%|3| 7/20 [00:01<00:03,  4.23it/\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  35%|3| 7/20 [00:01<00:03,  4.23it/\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  40%|4| 8/20 [00:01<00:02,  4.31it/\u001b[A[I 2024-02-06 20:38:23,666] Trial 50 finished with value: 0.4658963470294744 and parameters: {'lambda_l1': 8.5652013193307, 'lambda_l2': 3.5847790779053395e-05}. Best is trial 44 with value: 0.46578670092861435.\n",
      "\n",
      "regularization_factors, val_score: 0.465787:  40%|4| 8/20 [00:01<00:02,  4.31it/\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  40%|4| 8/20 [00:02<00:02,  4.31it/\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  45%|4| 9/20 [00:02<00:02,  4.28it/\u001b[A[I 2024-02-06 20:38:23,903] Trial 51 finished with value: 0.4660238354065888 and parameters: {'lambda_l1': 7.47299129144984, 'lambda_l2': 4.3494489895332546e-05}. Best is trial 44 with value: 0.46578670092861435.\n",
      "\n",
      "regularization_factors, val_score: 0.465787:  45%|4| 9/20 [00:02<00:02,  4.28it/\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  45%|4| 9/20 [00:02<00:02,  4.28it/\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  50%|5| 10/20 [00:02<00:02,  4.25it\u001b[A[I 2024-02-06 20:38:24,144] Trial 52 finished with value: 0.4659340154237854 and parameters: {'lambda_l1': 5.178536421035774, 'lambda_l2': 3.9533376575788065e-05}. Best is trial 44 with value: 0.46578670092861435.\n",
      "\n",
      "regularization_factors, val_score: 0.465787:  50%|5| 10/20 [00:02<00:02,  4.25it\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  50%|5| 10/20 [00:02<00:02,  4.25it\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  55%|5| 11/20 [00:02<00:02,  4.32it\u001b[A[I 2024-02-06 20:38:24,366] Trial 53 finished with value: 0.4658955379805248 and parameters: {'lambda_l1': 8.614883504616722, 'lambda_l2': 2.9420302135177702e-05}. Best is trial 44 with value: 0.46578670092861435.\n",
      "\n",
      "regularization_factors, val_score: 0.465787:  55%|5| 11/20 [00:02<00:02,  4.32it\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  55%|5| 11/20 [00:02<00:02,  4.32it\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  60%|6| 12/20 [00:02<00:01,  4.29it\u001b[A[I 2024-02-06 20:38:24,603] Trial 54 finished with value: 0.465822232147006 and parameters: {'lambda_l1': 9.444693272516266, 'lambda_l2': 3.255015206947457e-05}. Best is trial 44 with value: 0.46578670092861435.\n",
      "\n",
      "regularization_factors, val_score: 0.465787:  60%|6| 12/20 [00:02<00:01,  4.29it\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  60%|6| 12/20 [00:03<00:01,  4.29it\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  65%|6| 13/20 [00:03<00:01,  4.26it\u001b[A[I 2024-02-06 20:38:24,842] Trial 55 finished with value: 0.4658597574768515 and parameters: {'lambda_l1': 8.76961620972973, 'lambda_l2': 9.443190692466222e-07}. Best is trial 44 with value: 0.46578670092861435.\n",
      "\n",
      "regularization_factors, val_score: 0.465787:  65%|6| 13/20 [00:03<00:01,  4.26it\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  65%|6| 13/20 [00:03<00:01,  4.26it\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  70%|7| 14/20 [00:03<00:01,  4.33it\u001b[A[I 2024-02-06 20:38:25,063] Trial 56 finished with value: 0.46651035135317737 and parameters: {'lambda_l1': 0.015002090020082081, 'lambda_l2': 5.334409309976714e-07}. Best is trial 44 with value: 0.46578670092861435.\n",
      "\n",
      "regularization_factors, val_score: 0.465787:  70%|7| 14/20 [00:03<00:01,  4.33it\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  70%|7| 14/20 [00:03<00:01,  4.33it\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  75%|7| 15/20 [00:03<00:01,  4.33it\u001b[A[I 2024-02-06 20:38:25,295] Trial 57 finished with value: 0.4665104899142997 and parameters: {'lambda_l1': 1.7533577652390206e-08, 'lambda_l2': 2.156019200690326e-07}. Best is trial 44 with value: 0.46578670092861435.\n",
      "\n",
      "regularization_factors, val_score: 0.465787:  75%|7| 15/20 [00:03<00:01,  4.33it\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  75%|7| 15/20 [00:03<00:01,  4.33it\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  80%|8| 16/20 [00:03<00:00,  4.31it\u001b[A[I 2024-02-06 20:38:25,529] Trial 58 finished with value: 0.46649517626044756 and parameters: {'lambda_l1': 0.14197498146498777, 'lambda_l2': 0.005486274747072236}. Best is trial 44 with value: 0.46578670092861435.\n",
      "\n",
      "regularization_factors, val_score: 0.465787:  80%|8| 16/20 [00:03<00:00,  4.31it\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  80%|8| 16/20 [00:03<00:00,  4.31it\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  85%|8| 17/20 [00:03<00:00,  4.25it\u001b[A[I 2024-02-06 20:38:25,771] Trial 59 finished with value: 0.4663928959687513 and parameters: {'lambda_l1': 0.1938798126255503, 'lambda_l2': 1.0297863794610393e-06}. Best is trial 44 with value: 0.46578670092861435.\n",
      "\n",
      "regularization_factors, val_score: 0.465787:  85%|8| 17/20 [00:03<00:00,  4.25it\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  85%|8| 17/20 [00:04<00:00,  4.25it\u001b[A\n",
      "regularization_factors, val_score: 0.465787:  90%|9| 18/20 [00:04<00:00,  4.26it\u001b[A[I 2024-02-06 20:38:26,005] Trial 60 finished with value: 0.4666081203775734 and parameters: {'lambda_l1': 0.3702222624436396, 'lambda_l2': 0.0012328946676169947}. Best is trial 44 with value: 0.46578670092861435.\n",
      "\n",
      "regularization_factors, val_score: 0.465787:  90%|9| 18/20 [00:04<00:00,  4.26it\u001b[A\n",
      "regularization_factors, val_score: 0.465768:  90%|9| 18/20 [00:04<00:00,  4.26it\u001b[A\n",
      "regularization_factors, val_score: 0.465768:  95%|9| 19/20 [00:04<00:00,  4.25it\u001b[A[I 2024-02-06 20:38:26,241] Trial 61 finished with value: 0.46576810735389357 and parameters: {'lambda_l1': 9.043753849156383, 'lambda_l2': 3.0108956022921046e-06}. Best is trial 61 with value: 0.46576810735389357.\n",
      "\n",
      "regularization_factors, val_score: 0.465768:  95%|9| 19/20 [00:04<00:00,  4.25it\u001b[A\n",
      "regularization_factors, val_score: 0.465768:  95%|9| 19/20 [00:04<00:00,  4.25it\u001b[A\n",
      "regularization_factors, val_score: 0.465768: 100%|#| 20/20 [00:04<00:00,  4.13it\u001b[A[I 2024-02-06 20:38:26,500] Trial 62 finished with value: 0.46600531704396103 and parameters: {'lambda_l1': 8.288718540463318, 'lambda_l2': 2.2575590646268564e-06}. Best is trial 61 with value: 0.46576810735389357.\n",
      "regularization_factors, val_score: 0.465768: 100%|#| 20/20 [00:04<00:00,  4.25it\n",
      "\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "min_child_samples, val_score: 0.465768:   0%|             | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "min_child_samples, val_score: 0.465229:   0%|             | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "min_child_samples, val_score: 0.465229:  20%|#    | 1/5 [00:00<00:00,  4.23it/s]\u001b[A[I 2024-02-06 20:38:26,739] Trial 63 finished with value: 0.46522918026385995 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.46522918026385995.\n",
      "\n",
      "min_child_samples, val_score: 0.465229:  20%|#    | 1/5 [00:00<00:00,  4.23it/s]\u001b[A\n",
      "min_child_samples, val_score: 0.465229:  20%|#    | 1/5 [00:00<00:00,  4.23it/s]\u001b[A\n",
      "min_child_samples, val_score: 0.465229:  40%|##   | 2/5 [00:00<00:00,  4.23it/s]\u001b[A[I 2024-02-06 20:38:26,975] Trial 64 finished with value: 0.46569692695713466 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.46522918026385995.\n",
      "\n",
      "min_child_samples, val_score: 0.465229:  40%|##   | 2/5 [00:00<00:00,  4.23it/s]\u001b[A\n",
      "min_child_samples, val_score: 0.464979:  40%|##   | 2/5 [00:00<00:00,  4.23it/s]\u001b[A\n",
      "min_child_samples, val_score: 0.464979:  60%|###  | 3/5 [00:00<00:00,  4.11it/s]\u001b[A[I 2024-02-06 20:38:27,226] Trial 65 finished with value: 0.46497866951394873 and parameters: {'min_child_samples': 100}. Best is trial 65 with value: 0.46497866951394873.\n",
      "\n",
      "min_child_samples, val_score: 0.464979:  60%|###  | 3/5 [00:00<00:00,  4.11it/s]\u001b[A\n",
      "min_child_samples, val_score: 0.464864:  60%|###  | 3/5 [00:00<00:00,  4.11it/s]\u001b[A\n",
      "min_child_samples, val_score: 0.464864:  80%|#### | 4/5 [00:00<00:00,  4.18it/s]\u001b[A[I 2024-02-06 20:38:27,460] Trial 66 finished with value: 0.46486442823677854 and parameters: {'min_child_samples': 5}. Best is trial 66 with value: 0.46486442823677854.\n",
      "\n",
      "min_child_samples, val_score: 0.464864:  80%|#### | 4/5 [00:00<00:00,  4.18it/s]\u001b[A\n",
      "min_child_samples, val_score: 0.464829:  80%|#### | 4/5 [00:01<00:00,  4.18it/s]\u001b[A\n",
      "min_child_samples, val_score: 0.464829: 100%|#####| 5/5 [00:01<00:00,  4.19it/s]\u001b[A[I 2024-02-06 20:38:27,698] Trial 67 finished with value: 0.4648287931581653 and parameters: {'min_child_samples': 10}. Best is trial 67 with value: 0.4648287931581653.\n",
      "min_child_samples, val_score: 0.464829: 100%|#####| 5/5 [00:01<00:00,  4.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "gbt_data = train_series.merge(forecast, on='ds', how='left')\n",
    "train_gbt, val_gbt = train_test_split(gbt_data, test_size=0.15, random_state=42)\n",
    "\n",
    "lgbm_os = OptunaLGBMRegressor(n_estimators=300, learning_rate=0.01, metric='mape', seed=42)\n",
    "\n",
    "lgbm_os.fit(\n",
    "    train_gbt.drop(['ds', 'y'], axis=1), \n",
    "    train_gbt.y.values,\n",
    "    val_gbt.drop(['ds', 'y'], axis=1),\n",
    "    val_gbt.y.values\n",
    ")\n",
    "\n",
    "test_gbt = new_test_series.merge(forecast, on='ds', how='left')\n",
    "preds = lgbm_os.predict(test_gbt.drop(['ds'], axis=1)) # preds = lgbm.predict(test_gbt.drop(['ds', 'y'], axis=1))\n",
    "\n",
    "forecast_df = test_gbt[['ds']].copy() # forecast_df = test_gbt[['ds', 'y', 'yhat']].copy()\n",
    "forecast_df['gbt_yhat'] = preds\n",
    "\n",
    "# forecast_df['gbt_yhat'] - предикт модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'model_os.h5py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/Users/andreyboriskin/PycharmProjects/predprof/models/model_os/' + filename, 'wb') as file:\n",
    "\tpickle.dump(lgbm_os, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Влажность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wl = df.copy()\n",
    "df_wl = df_wl.rename(columns={'Относительная влажность воздуха': 'y'})\n",
    "df_wl.drop(df_wl.loc[df_wl['y'] == '   '].index, inplace=True)\n",
    "df_wl['y'] = df_wl['y'].astype('int64')\n",
    "data = pd.DataFrame(columns=['ds', 'y'])\n",
    "data['ds'] = df_wl.date\n",
    "data['y'] = df_wl.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_series = data # [data.ds < (data.ds.max() - timedelta(days=30))]\n",
    "# test_series = data[data.ds >= (data.ds.max() - timedelta(days=30))].drop(['y'], axis=1)\n",
    "start_date = '2022-12-31'\n",
    "end_date = '2023-01-07'\n",
    "\n",
    "start = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "end = datetime.strptime(end_date, '%Y-%m-%d')   \n",
    "\n",
    "daterange = [(start + timedelta(days=x)).strftime('%Y-%m-%d') for x in range(0, (end-start).days)]\n",
    "new_test_series = pd.DataFrame(pd.to_datetime(daterange), columns=['ds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:41:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:41:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "fb_wl = prophet.Prophet()\n",
    "\n",
    "with suppress_stdout_stderr():\n",
    "    fb_wl.fit(train_series)\n",
    "\n",
    "predictions = fb_wl.make_future_dataframe(periods=len(new_test_series), freq='D')\n",
    "forecast = fb_wl.predict(predictions)\n",
    "\n",
    "# v_fb_df = test_series.copy()\n",
    "# v_fb_df = v_fb_df.merge(forecast[['ds', 'yhat']], on='ds', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'fb_model_wl.h5py'\n",
    "with open('/Users/andreyboriskin/PycharmProjects/predprof/models/model_wl/' + filename, 'wb') as file:\n",
    "\tpickle.dump(fb_wl, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-06 20:41:19,816] A new study created in memory with name: no-name-09ec0aa4-d230-4bf8-90db-6bed6ddf4e75\n",
      "\n",
      "  0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction, val_score: inf:   0%|                   | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.208844:   0%|              | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.208844:  14%|8     | 1/7 [00:00<00:03,  1.54it/s]\u001b[A[I 2024-02-06 20:41:20,470] Trial 0 finished with value: 0.20884399567835749 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.20884399567835749.\n",
      "\n",
      "feature_fraction, val_score: 0.208844:  14%|8     | 1/7 [00:00<00:03,  1.54it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.208822:  14%|8     | 1/7 [00:01<00:03,  1.54it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.208822:  29%|#7    | 2/7 [00:01<00:03,  1.48it/s]\u001b[A[I 2024-02-06 20:41:21,160] Trial 1 finished with value: 0.20882228634284475 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.20882228634284475.\n",
      "\n",
      "feature_fraction, val_score: 0.208822:  29%|#7    | 2/7 [00:01<00:03,  1.48it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.208822:  29%|#7    | 2/7 [00:01<00:03,  1.48it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.208822:  43%|##5   | 3/7 [00:01<00:02,  1.51it/s]\u001b[A[I 2024-02-06 20:41:21,812] Trial 2 finished with value: 0.20888935590574453 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.20882228634284475.\n",
      "\n",
      "feature_fraction, val_score: 0.208822:  43%|##5   | 3/7 [00:01<00:02,  1.51it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.208822:  43%|##5   | 3/7 [00:02<00:02,  1.51it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.208822:  57%|###4  | 4/7 [00:02<00:02,  1.47it/s]\u001b[A[I 2024-02-06 20:41:22,517] Trial 3 finished with value: 0.208826905647246 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.20882228634284475.\n",
      "\n",
      "feature_fraction, val_score: 0.208822:  57%|###4  | 4/7 [00:02<00:02,  1.47it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.208822:  57%|###4  | 4/7 [00:03<00:02,  1.47it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.208822:  71%|####2 | 5/7 [00:03<00:01,  1.44it/s]\u001b[A[I 2024-02-06 20:41:23,243] Trial 4 finished with value: 0.20882418615415443 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.20882228634284475.\n",
      "\n",
      "feature_fraction, val_score: 0.208822:  71%|####2 | 5/7 [00:03<00:01,  1.44it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.208822:  71%|####2 | 5/7 [00:04<00:01,  1.44it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.208822:  86%|#####1| 6/7 [00:04<00:00,  1.51it/s]\u001b[A[I 2024-02-06 20:41:23,838] Trial 5 finished with value: 0.20892528586563144 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.20882228634284475.\n",
      "\n",
      "feature_fraction, val_score: 0.208822:  86%|#####1| 6/7 [00:04<00:00,  1.51it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.208786:  86%|#####1| 6/7 [00:04<00:00,  1.51it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.208786: 100%|######| 7/7 [00:04<00:00,  1.49it/s]\u001b[A[I 2024-02-06 20:41:24,526] Trial 6 finished with value: 0.20878628848187347 and parameters: {'feature_fraction': 0.7}. Best is trial 6 with value: 0.20878628848187347.\n",
      "feature_fraction, val_score: 0.208786: 100%|######| 7/7 [00:04<00:00,  1.49it/s]\n",
      "\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "num_leaves, val_score: 0.208786:   0%|                   | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "num_leaves, val_score: 0.206572:   0%|                   | 0/20 [00:02<?, ?it/s]\u001b[A\n",
      "num_leaves, val_score: 0.206572:   5%|5          | 1/20 [00:02<00:38,  2.03s/it]\u001b[A[I 2024-02-06 20:41:26,563] Trial 7 finished with value: 0.20657183918017108 and parameters: {'num_leaves': 228}. Best is trial 7 with value: 0.20657183918017108.\n",
      "\n",
      "num_leaves, val_score: 0.206572:   5%|5          | 1/20 [00:02<00:38,  2.03s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206572:   5%|5          | 1/20 [00:03<00:38,  2.03s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206572:  10%|#1         | 2/20 [00:03<00:28,  1.56s/it]\u001b[A[I 2024-02-06 20:41:27,794] Trial 8 finished with value: 0.2070604658185043 and parameters: {'num_leaves': 101}. Best is trial 7 with value: 0.20657183918017108.\n",
      "\n",
      "num_leaves, val_score: 0.206572:  10%|#1         | 2/20 [00:03<00:28,  1.56s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206572:  10%|#1         | 2/20 [00:04<00:28,  1.56s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206572:  15%|#6         | 3/20 [00:04<00:27,  1.63s/it]\u001b[A[I 2024-02-06 20:41:29,505] Trial 9 finished with value: 0.2066694705786417 and parameters: {'num_leaves': 179}. Best is trial 7 with value: 0.20657183918017108.\n",
      "\n",
      "num_leaves, val_score: 0.206572:  15%|#6         | 3/20 [00:04<00:27,  1.63s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206572:  15%|#6         | 3/20 [00:07<00:27,  1.63s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206572:  20%|##2        | 4/20 [00:07<00:29,  1.85s/it]\u001b[A[I 2024-02-06 20:41:31,687] Trial 10 finished with value: 0.20678394079039858 and parameters: {'num_leaves': 255}. Best is trial 7 with value: 0.20657183918017108.\n",
      "\n",
      "num_leaves, val_score: 0.206572:  20%|##2        | 4/20 [00:07<00:29,  1.85s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206572:  20%|##2        | 4/20 [00:09<00:29,  1.85s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206572:  25%|##7        | 5/20 [00:09<00:28,  1.89s/it]\u001b[A[I 2024-02-06 20:41:33,646] Trial 11 finished with value: 0.206630360413148 and parameters: {'num_leaves': 219}. Best is trial 7 with value: 0.20657183918017108.\n",
      "\n",
      "num_leaves, val_score: 0.206572:  25%|##7        | 5/20 [00:09<00:28,  1.89s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206553:  25%|##7        | 5/20 [00:11<00:28,  1.89s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206553:  30%|###3       | 6/20 [00:11<00:27,  1.95s/it]\u001b[A[I 2024-02-06 20:41:35,721] Trial 12 finished with value: 0.20655319448170165 and parameters: {'num_leaves': 237}. Best is trial 12 with value: 0.20655319448170165.\n",
      "\n",
      "num_leaves, val_score: 0.206553:  30%|###3       | 6/20 [00:11<00:27,  1.95s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206553:  30%|###3       | 6/20 [00:12<00:27,  1.95s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206553:  35%|###8       | 7/20 [00:12<00:24,  1.85s/it]\u001b[A[I 2024-02-06 20:41:37,362] Trial 13 finished with value: 0.20673747860431135 and parameters: {'num_leaves': 167}. Best is trial 12 with value: 0.20655319448170165.\n",
      "\n",
      "num_leaves, val_score: 0.206553:  35%|###8       | 7/20 [00:12<00:24,  1.85s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206553:  35%|###8       | 7/20 [00:13<00:24,  1.85s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206553:  40%|####4      | 8/20 [00:13<00:16,  1.41s/it]\u001b[A[I 2024-02-06 20:41:37,832] Trial 14 finished with value: 0.2104572481679603 and parameters: {'num_leaves': 14}. Best is trial 12 with value: 0.20655319448170165.\n",
      "\n",
      "num_leaves, val_score: 0.206553:  40%|####4      | 8/20 [00:13<00:16,  1.41s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206497:  40%|####4      | 8/20 [00:15<00:16,  1.41s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206497:  45%|####9      | 9/20 [00:15<00:18,  1.65s/it]\u001b[A[I 2024-02-06 20:41:40,022] Trial 15 finished with value: 0.20649704887690293 and parameters: {'num_leaves': 256}. Best is trial 15 with value: 0.20649704887690293.\n",
      "\n",
      "num_leaves, val_score: 0.206497:  45%|####9      | 9/20 [00:15<00:18,  1.65s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206497:  45%|####9      | 9/20 [00:17<00:18,  1.65s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206497:  50%|#####     | 10/20 [00:17<00:18,  1.82s/it]\u001b[A[I 2024-02-06 20:41:42,207] Trial 16 finished with value: 0.20678394079039858 and parameters: {'num_leaves': 255}. Best is trial 15 with value: 0.20649704887690293.\n",
      "\n",
      "num_leaves, val_score: 0.206497:  50%|#####     | 10/20 [00:17<00:18,  1.82s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206497:  50%|#####     | 10/20 [00:18<00:18,  1.82s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206497:  55%|#####5    | 11/20 [00:18<00:14,  1.62s/it]\u001b[A[I 2024-02-06 20:41:43,391] Trial 17 finished with value: 0.2073067671845735 and parameters: {'num_leaves': 95}. Best is trial 15 with value: 0.20649704887690293.\n",
      "\n",
      "num_leaves, val_score: 0.206497:  55%|#####5    | 11/20 [00:18<00:14,  1.62s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206237:  55%|#####5    | 11/20 [00:20<00:14,  1.62s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206237:  60%|######    | 12/20 [00:20<00:13,  1.66s/it]\u001b[A[I 2024-02-06 20:41:45,148] Trial 18 finished with value: 0.20623684072400553 and parameters: {'num_leaves': 185}. Best is trial 18 with value: 0.20623684072400553.\n",
      "\n",
      "num_leaves, val_score: 0.206237:  60%|######    | 12/20 [00:20<00:13,  1.66s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206237:  60%|######    | 12/20 [00:22<00:13,  1.66s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206237:  65%|######5   | 13/20 [00:22<00:11,  1.68s/it]\u001b[A[I 2024-02-06 20:41:46,850] Trial 19 finished with value: 0.20674214619941697 and parameters: {'num_leaves': 176}. Best is trial 18 with value: 0.20623684072400553.\n",
      "\n",
      "num_leaves, val_score: 0.206237:  65%|######5   | 13/20 [00:22<00:11,  1.68s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206237:  65%|######5   | 13/20 [00:23<00:11,  1.68s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206237:  70%|#######   | 14/20 [00:23<00:09,  1.64s/it]\u001b[A[I 2024-02-06 20:41:48,392] Trial 20 finished with value: 0.2066452847733138 and parameters: {'num_leaves': 151}. Best is trial 18 with value: 0.20623684072400553.\n",
      "\n",
      "num_leaves, val_score: 0.206237:  70%|#######   | 14/20 [00:23<00:09,  1.64s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206237:  70%|#######   | 14/20 [00:25<00:09,  1.64s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206237:  75%|#######5  | 15/20 [00:25<00:08,  1.72s/it]\u001b[A[I 2024-02-06 20:41:50,310] Trial 21 finished with value: 0.20648886468604355 and parameters: {'num_leaves': 212}. Best is trial 18 with value: 0.20623684072400553.\n",
      "\n",
      "num_leaves, val_score: 0.206237:  75%|#######5  | 15/20 [00:25<00:08,  1.72s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206237:  75%|#######5  | 15/20 [00:27<00:08,  1.72s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206237:  80%|########  | 16/20 [00:27<00:07,  1.75s/it]\u001b[A[I 2024-02-06 20:41:52,140] Trial 22 finished with value: 0.2066217064772275 and parameters: {'num_leaves': 197}. Best is trial 18 with value: 0.20623684072400553.\n",
      "\n",
      "num_leaves, val_score: 0.206237:  80%|########  | 16/20 [00:27<00:07,  1.75s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206237:  80%|########  | 16/20 [00:29<00:07,  1.75s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206237:  85%|########5 | 17/20 [00:29<00:05,  1.80s/it]\u001b[A[I 2024-02-06 20:41:54,039] Trial 23 finished with value: 0.20668821987166913 and parameters: {'num_leaves': 209}. Best is trial 18 with value: 0.20623684072400553.\n",
      "\n",
      "num_leaves, val_score: 0.206237:  85%|########5 | 17/20 [00:29<00:05,  1.80s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206237:  85%|########5 | 17/20 [00:30<00:05,  1.80s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206237:  90%|######### | 18/20 [00:30<00:03,  1.68s/it]\u001b[A[I 2024-02-06 20:41:55,456] Trial 24 finished with value: 0.20675735011590676 and parameters: {'num_leaves': 132}. Best is trial 18 with value: 0.20623684072400553.\n",
      "\n",
      "num_leaves, val_score: 0.206237:  90%|######### | 18/20 [00:30<00:03,  1.68s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206237:  90%|######### | 18/20 [00:32<00:03,  1.68s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206237:  95%|#########5| 19/20 [00:32<00:01,  1.73s/it]\u001b[A[I 2024-02-06 20:41:57,297] Trial 25 finished with value: 0.20646300018852196 and parameters: {'num_leaves': 200}. Best is trial 18 with value: 0.20623684072400553.\n",
      "\n",
      "num_leaves, val_score: 0.206237:  95%|#########5| 19/20 [00:32<00:01,  1.73s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206237:  95%|#########5| 19/20 [00:34<00:01,  1.73s/it]\u001b[A\n",
      "num_leaves, val_score: 0.206237: 100%|##########| 20/20 [00:34<00:00,  1.75s/it]\u001b[A[I 2024-02-06 20:41:59,100] Trial 26 finished with value: 0.20674613427443353 and parameters: {'num_leaves': 193}. Best is trial 18 with value: 0.20623684072400553.\n",
      "num_leaves, val_score: 0.206237: 100%|##########| 20/20 [00:34<00:00,  1.73s/it]\n",
      "\n",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "bagging, val_score: 0.206237:   0%|                      | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "bagging, val_score: 0.206237:   0%|                      | 0/10 [00:02<?, ?it/s]\u001b[A\n",
      "bagging, val_score: 0.206237:  10%|#4            | 1/10 [00:02<00:20,  2.24s/it]\u001b[A[I 2024-02-06 20:42:01,346] Trial 27 finished with value: 0.20884737279425875 and parameters: {'bagging_fraction': 0.4559836290568791, 'bagging_freq': 5}. Best is trial 27 with value: 0.20884737279425875.\n",
      "\n",
      "bagging, val_score: 0.206237:  10%|#4            | 1/10 [00:02<00:20,  2.24s/it]\u001b[A\n",
      "bagging, val_score: 0.206149:  10%|#4            | 1/10 [00:04<00:20,  2.24s/it]\u001b[A\n",
      "bagging, val_score: 0.206149:  20%|##8           | 2/10 [00:04<00:16,  2.02s/it]\u001b[A[I 2024-02-06 20:42:03,216] Trial 28 finished with value: 0.20614929939542231 and parameters: {'bagging_fraction': 0.977067361366164, 'bagging_freq': 1}. Best is trial 28 with value: 0.20614929939542231.\n",
      "\n",
      "bagging, val_score: 0.206149:  20%|##8           | 2/10 [00:04<00:16,  2.02s/it]\u001b[A\n",
      "bagging, val_score: 0.206149:  20%|##8           | 2/10 [00:05<00:16,  2.02s/it]\u001b[A\n",
      "bagging, val_score: 0.206149:  30%|####2         | 3/10 [00:05<00:13,  1.93s/it]\u001b[A[I 2024-02-06 20:42:05,029] Trial 29 finished with value: 0.2065391524686022 and parameters: {'bagging_fraction': 0.9912975612308759, 'bagging_freq': 1}. Best is trial 28 with value: 0.20614929939542231.\n",
      "\n",
      "bagging, val_score: 0.206149:  30%|####2         | 3/10 [00:05<00:13,  1.93s/it]\u001b[A\n",
      "bagging, val_score: 0.206149:  30%|####2         | 3/10 [00:07<00:13,  1.93s/it]\u001b[A\n",
      "bagging, val_score: 0.206149:  40%|#####6        | 4/10 [00:07<00:11,  1.93s/it]\u001b[A[I 2024-02-06 20:42:06,957] Trial 30 finished with value: 0.2068055105390709 and parameters: {'bagging_fraction': 0.9989561492707838, 'bagging_freq': 1}. Best is trial 28 with value: 0.20614929939542231.\n",
      "\n",
      "bagging, val_score: 0.206149:  40%|#####6        | 4/10 [00:07<00:11,  1.93s/it]\u001b[A\n",
      "bagging, val_score: 0.206149:  40%|#####6        | 4/10 [00:10<00:11,  1.93s/it]\u001b[A\n",
      "bagging, val_score: 0.206149:  50%|#######       | 5/10 [00:10<00:10,  2.07s/it]\u001b[A[I 2024-02-06 20:42:09,293] Trial 31 finished with value: 0.20728963465879746 and parameters: {'bagging_fraction': 0.7310400518441117, 'bagging_freq': 7}. Best is trial 28 with value: 0.20614929939542231.\n",
      "\n",
      "bagging, val_score: 0.206149:  50%|#######       | 5/10 [00:10<00:10,  2.07s/it]\u001b[A\n",
      "bagging, val_score: 0.206149:  50%|#######       | 5/10 [00:12<00:10,  2.07s/it]\u001b[A\n",
      "bagging, val_score: 0.206149:  60%|########4     | 6/10 [00:12<00:08,  2.18s/it]\u001b[A[I 2024-02-06 20:42:11,680] Trial 32 finished with value: 0.20654328389653287 and parameters: {'bagging_fraction': 0.7551410042038461, 'bagging_freq': 3}. Best is trial 28 with value: 0.20614929939542231.\n",
      "\n",
      "bagging, val_score: 0.206149:  60%|########4     | 6/10 [00:12<00:08,  2.18s/it]\u001b[A\n",
      "bagging, val_score: 0.206149:  60%|########4     | 6/10 [00:14<00:08,  2.18s/it]\u001b[A\n",
      "bagging, val_score: 0.206149:  70%|#########7    | 7/10 [00:14<00:06,  2.24s/it]\u001b[A[I 2024-02-06 20:42:14,031] Trial 33 finished with value: 0.20642897923295667 and parameters: {'bagging_fraction': 0.8605851870014308, 'bagging_freq': 3}. Best is trial 28 with value: 0.20614929939542231.\n",
      "\n",
      "bagging, val_score: 0.206149:  70%|#########7    | 7/10 [00:14<00:06,  2.24s/it]\u001b[A\n",
      "bagging, val_score: 0.206149:  70%|#########7    | 7/10 [00:17<00:06,  2.24s/it]\u001b[A\n",
      "bagging, val_score: 0.206149:  80%|###########2  | 8/10 [00:17<00:04,  2.27s/it]\u001b[A[I 2024-02-06 20:42:16,384] Trial 34 finished with value: 0.20621197295524724 and parameters: {'bagging_fraction': 0.8697106930698613, 'bagging_freq': 3}. Best is trial 28 with value: 0.20614929939542231.\n",
      "\n",
      "bagging, val_score: 0.206149:  80%|###########2  | 8/10 [00:17<00:04,  2.27s/it]\u001b[A\n",
      "bagging, val_score: 0.206149:  80%|###########2  | 8/10 [00:19<00:04,  2.27s/it]\u001b[A\n",
      "bagging, val_score: 0.206149:  90%|############6 | 9/10 [00:19<00:02,  2.29s/it]\u001b[A[I 2024-02-06 20:42:18,713] Trial 35 finished with value: 0.20647688880562678 and parameters: {'bagging_fraction': 0.8781656014972455, 'bagging_freq': 3}. Best is trial 28 with value: 0.20614929939542231.\n",
      "\n",
      "bagging, val_score: 0.206149:  90%|############6 | 9/10 [00:19<00:02,  2.29s/it]\u001b[A\n",
      "bagging, val_score: 0.206149:  90%|############6 | 9/10 [00:21<00:02,  2.29s/it]\u001b[A\n",
      "bagging, val_score: 0.206149: 100%|#############| 10/10 [00:21<00:00,  2.30s/it]\u001b[A[I 2024-02-06 20:42:21,025] Trial 36 finished with value: 0.20648968535292023 and parameters: {'bagging_fraction': 0.8518565974114615, 'bagging_freq': 3}. Best is trial 28 with value: 0.20614929939542231.\n",
      "bagging, val_score: 0.206149: 100%|#############| 10/10 [00:21<00:00,  2.19s/it]\n",
      "\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.206149:   0%|       | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.206149:   0%|       | 0/6 [00:01<?, ?it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.206149:  17%|1| 1/6 [00:01<00:08,  1.77s/i\u001b[A[I 2024-02-06 20:42:22,800] Trial 37 finished with value: 0.2064354676641024 and parameters: {'feature_fraction': 0.652}. Best is trial 37 with value: 0.2064354676641024.\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.206149:  17%|1| 1/6 [00:01<00:08,  1.77s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.206149:  17%|1| 1/6 [00:03<00:08,  1.77s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.206149:  33%|3| 2/6 [00:03<00:06,  1.75s/i\u001b[A[I 2024-02-06 20:42:24,533] Trial 38 finished with value: 0.2064478519084219 and parameters: {'feature_fraction': 0.62}. Best is trial 37 with value: 0.2064354676641024.\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.206149:  33%|3| 2/6 [00:03<00:06,  1.75s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.206149:  33%|3| 2/6 [00:05<00:06,  1.75s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.206149:  50%|5| 3/6 [00:05<00:05,  1.81s/i\u001b[A[I 2024-02-06 20:42:26,408] Trial 39 finished with value: 0.2062910618247684 and parameters: {'feature_fraction': 0.7799999999999999}. Best is trial 39 with value: 0.2062910618247684.\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.206149:  50%|5| 3/6 [00:05<00:05,  1.81s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.206149:  50%|5| 3/6 [00:07<00:05,  1.81s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.206149:  67%|6| 4/6 [00:07<00:03,  1.81s/i\u001b[A[I 2024-02-06 20:42:28,226] Trial 40 finished with value: 0.20614929939542231 and parameters: {'feature_fraction': 0.716}. Best is trial 40 with value: 0.20614929939542231.\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.206149:  67%|6| 4/6 [00:07<00:03,  1.81s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.206149:  67%|6| 4/6 [00:09<00:03,  1.81s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.206149:  83%|8| 5/6 [00:09<00:01,  1.81s/i\u001b[A[I 2024-02-06 20:42:30,038] Trial 41 finished with value: 0.20614929939542231 and parameters: {'feature_fraction': 0.748}. Best is trial 40 with value: 0.20614929939542231.\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.206149:  83%|8| 5/6 [00:09<00:01,  1.81s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.206149:  83%|8| 5/6 [00:10<00:01,  1.81s/i\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.206149: 100%|#| 6/6 [00:10<00:00,  1.79s/i\u001b[A[I 2024-02-06 20:42:31,798] Trial 42 finished with value: 0.2064354676641024 and parameters: {'feature_fraction': 0.6839999999999999}. Best is trial 40 with value: 0.20614929939542231.\n",
      "feature_fraction_stage2, val_score: 0.206149: 100%|#| 6/6 [00:10<00:00,  1.80s/i\n",
      "\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.206149:   0%|       | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.206149:   0%|       | 0/20 [00:01<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.206149:   5%| | 1/20 [00:01<00:35,  1.88s/i\u001b[A[I 2024-02-06 20:42:33,682] Trial 43 finished with value: 0.20614929941171112 and parameters: {'lambda_l1': 2.7817135673176855e-07, 'lambda_l2': 5.3521157170114504e-08}. Best is trial 43 with value: 0.20614929941171112.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:   5%| | 1/20 [00:01<00:35,  1.88s/i\u001b[A\n",
      "regularization_factors, val_score: 0.206149:   5%| | 1/20 [00:03<00:35,  1.88s/i\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  10%|1| 2/20 [00:03<00:33,  1.88s/i\u001b[A[I 2024-02-06 20:42:35,556] Trial 44 finished with value: 0.20614929940453716 and parameters: {'lambda_l1': 9.11786111013625e-08, 'lambda_l2': 3.830889647590505e-08}. Best is trial 44 with value: 0.20614929940453716.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:  10%|1| 2/20 [00:03<00:33,  1.88s/i\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  10%|1| 2/20 [00:05<00:33,  1.88s/i\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  15%|1| 3/20 [00:05<00:31,  1.87s/i\u001b[A[I 2024-02-06 20:42:37,429] Trial 45 finished with value: 0.20614929939971624 and parameters: {'lambda_l1': 5.834673154816487e-08, 'lambda_l2': 1.717191164604617e-08}. Best is trial 45 with value: 0.20614929939971624.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:  15%|1| 3/20 [00:05<00:31,  1.87s/i\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  15%|1| 3/20 [00:07<00:31,  1.87s/i\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  20%|2| 4/20 [00:07<00:29,  1.87s/i\u001b[A[I 2024-02-06 20:42:39,301] Trial 46 finished with value: 0.20614929939813642 and parameters: {'lambda_l1': 4.286892259881832e-08, 'lambda_l2': 1.0483484533738676e-08}. Best is trial 46 with value: 0.20614929939813642.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:  20%|2| 4/20 [00:07<00:29,  1.87s/i\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  20%|2| 4/20 [00:09<00:29,  1.87s/i\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  25%|2| 5/20 [00:09<00:28,  1.87s/i\u001b[A[I 2024-02-06 20:42:41,174] Trial 47 finished with value: 0.20614929939772866 and parameters: {'lambda_l1': 1.0747844471845296e-08, 'lambda_l2': 1.0967621717295451e-08}. Best is trial 47 with value: 0.20614929939772866.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:  25%|2| 5/20 [00:09<00:28,  1.87s/i\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  25%|2| 5/20 [00:11<00:28,  1.87s/i\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  30%|3| 6/20 [00:11<00:26,  1.91s/i\u001b[A[I 2024-02-06 20:42:43,143] Trial 48 finished with value: 0.2063679785236955 and parameters: {'lambda_l1': 1.1143018773945568, 'lambda_l2': 0.03406708199586505}. Best is trial 47 with value: 0.20614929939772866.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:  30%|3| 6/20 [00:11<00:26,  1.91s/i\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  30%|3| 6/20 [00:13<00:26,  1.91s/i\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  35%|3| 7/20 [00:13<00:24,  1.90s/i\u001b[A[I 2024-02-06 20:42:45,029] Trial 49 finished with value: 0.20614930692549077 and parameters: {'lambda_l1': 0.00014080957149815312, 'lambda_l2': 2.424412723728255e-05}. Best is trial 47 with value: 0.20614929939772866.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:  35%|3| 7/20 [00:13<00:24,  1.90s/i\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  35%|3| 7/20 [00:15<00:24,  1.90s/i\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  40%|4| 8/20 [00:15<00:22,  1.89s/i\u001b[A[I 2024-02-06 20:42:46,910] Trial 50 finished with value: 0.20614930313067026 and parameters: {'lambda_l1': 3.123996268276766e-05, 'lambda_l2': 1.586633490596541e-05}. Best is trial 47 with value: 0.20614929939772866.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:  40%|4| 8/20 [00:15<00:22,  1.89s/i\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  40%|4| 8/20 [00:16<00:22,  1.89s/i\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  45%|4| 9/20 [00:16<00:20,  1.89s/i\u001b[A[I 2024-02-06 20:42:48,783] Trial 51 finished with value: 0.20614929939760213 and parameters: {'lambda_l1': 1.0235374172481741e-08, 'lambda_l2': 1.0129589814912743e-08}. Best is trial 51 with value: 0.20614929939760213.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:  45%|4| 9/20 [00:16<00:20,  1.89s/i\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  45%|4| 9/20 [00:18<00:20,  1.89s/i\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  50%|5| 10/20 [00:18<00:18,  1.88s/\u001b[A[I 2024-02-06 20:42:50,661] Trial 52 finished with value: 0.20614929939777366 and parameters: {'lambda_l1': 1.0090353317339403e-08, 'lambda_l2': 1.1167520144785104e-08}. Best is trial 51 with value: 0.20614929939760213.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:  50%|5| 10/20 [00:18<00:18,  1.88s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  50%|5| 10/20 [00:20<00:18,  1.88s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  55%|5| 11/20 [00:20<00:17,  1.89s/\u001b[A[I 2024-02-06 20:42:52,561] Trial 53 finished with value: 0.20614929964526385 and parameters: {'lambda_l1': 1.0295242423750642e-08, 'lambda_l2': 1.2580272756637712e-06}. Best is trial 51 with value: 0.20614929939760213.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:  55%|5| 11/20 [00:20<00:17,  1.89s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  55%|5| 11/20 [00:22<00:17,  1.89s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  60%|6| 12/20 [00:22<00:15,  1.89s/\u001b[A[I 2024-02-06 20:42:54,448] Trial 54 finished with value: 0.2061492996523712 and parameters: {'lambda_l1': 4.218783330905862e-06, 'lambda_l2': 8.787811733612559e-07}. Best is trial 51 with value: 0.20614929939760213.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:  60%|6| 12/20 [00:22<00:15,  1.89s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  60%|6| 12/20 [00:24<00:15,  1.89s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  65%|6| 13/20 [00:24<00:13,  1.92s/\u001b[A[I 2024-02-06 20:42:56,426] Trial 55 finished with value: 0.20774697108824128 and parameters: {'lambda_l1': 0.03197165384695386, 'lambda_l2': 9.861751339846649}. Best is trial 51 with value: 0.20614929939760213.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:  65%|6| 13/20 [00:24<00:13,  1.92s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  65%|6| 13/20 [00:26<00:13,  1.92s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  70%|7| 14/20 [00:26<00:11,  1.91s/\u001b[A[I 2024-02-06 20:42:58,320] Trial 56 finished with value: 0.20614929955189348 and parameters: {'lambda_l1': 1.9826246683519875e-06, 'lambda_l2': 5.913416571727097e-07}. Best is trial 51 with value: 0.20614929939760213.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:  70%|7| 14/20 [00:26<00:11,  1.91s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  70%|7| 14/20 [00:28<00:11,  1.91s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  75%|7| 15/20 [00:28<00:09,  1.92s/\u001b[A[I 2024-02-06 20:43:00,261] Trial 57 finished with value: 0.20616778989450124 and parameters: {'lambda_l1': 1.027817919147334e-08, 'lambda_l2': 0.001771165712225943}. Best is trial 51 with value: 0.20614929939760213.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:  75%|7| 15/20 [00:28<00:09,  1.92s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  75%|7| 15/20 [00:30<00:09,  1.92s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  80%|8| 16/20 [00:30<00:07,  1.91s/\u001b[A[I 2024-02-06 20:43:02,153] Trial 58 finished with value: 0.20614929946910832 and parameters: {'lambda_l1': 1.0393844840155174e-06, 'lambda_l2': 2.7155931376075277e-07}. Best is trial 51 with value: 0.20614929939760213.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:  80%|8| 16/20 [00:30<00:07,  1.91s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  80%|8| 16/20 [00:32<00:07,  1.91s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  85%|8| 17/20 [00:32<00:05,  1.92s/\u001b[A[I 2024-02-06 20:43:04,078] Trial 59 finished with value: 0.2062229887040414 and parameters: {'lambda_l1': 0.0014507952986122525, 'lambda_l2': 1.162415201207547e-05}. Best is trial 51 with value: 0.20614929939760213.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:  85%|8| 17/20 [00:32<00:05,  1.92s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  85%|8| 17/20 [00:34<00:05,  1.92s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  90%|9| 18/20 [00:34<00:03,  1.92s/\u001b[A[I 2024-02-06 20:43:06,007] Trial 60 finished with value: 0.20614929940027782 and parameters: {'lambda_l1': 1.6388152343649792e-07, 'lambda_l2': 1.0211605008241322e-08}. Best is trial 51 with value: 0.20614929939760213.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:  90%|9| 18/20 [00:34<00:03,  1.92s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  90%|9| 18/20 [00:36<00:03,  1.92s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  95%|9| 19/20 [00:36<00:01,  1.90s/\u001b[A[I 2024-02-06 20:43:07,876] Trial 61 finished with value: 0.206149299397771 and parameters: {'lambda_l1': 1.5872519751198503e-08, 'lambda_l2': 1.0194553758973598e-08}. Best is trial 51 with value: 0.20614929939760213.\n",
      "\n",
      "regularization_factors, val_score: 0.206149:  95%|9| 19/20 [00:36<00:01,  1.90s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149:  95%|9| 19/20 [00:37<00:01,  1.90s/\u001b[A\n",
      "regularization_factors, val_score: 0.206149: 100%|#| 20/20 [00:37<00:00,  1.90s/\u001b[A[I 2024-02-06 20:43:09,757] Trial 62 finished with value: 0.20614929941635224 and parameters: {'lambda_l1': 1.0011680262682592e-08, 'lambda_l2': 1.015659016386167e-07}. Best is trial 51 with value: 0.20614929939760213.\n",
      "regularization_factors, val_score: 0.206149: 100%|#| 20/20 [00:37<00:00,  1.90s/\n",
      "\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "min_child_samples, val_score: 0.206149:   0%|             | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "min_child_samples, val_score: 0.206149:   0%|             | 0/5 [00:01<?, ?it/s]\u001b[A\n",
      "min_child_samples, val_score: 0.206149:  20%|#    | 1/5 [00:01<00:06,  1.71s/it]\u001b[A[I 2024-02-06 20:43:11,474] Trial 63 finished with value: 0.2063886750258265 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.2063886750258265.\n",
      "\n",
      "min_child_samples, val_score: 0.206149:  20%|#    | 1/5 [00:01<00:06,  1.71s/it]\u001b[A\n",
      "min_child_samples, val_score: 0.205886:  20%|#    | 1/5 [00:03<00:06,  1.71s/it]\u001b[A\n",
      "min_child_samples, val_score: 0.205886:  40%|##   | 2/5 [00:03<00:05,  1.75s/it]\u001b[A[I 2024-02-06 20:43:13,243] Trial 64 finished with value: 0.20588642989852504 and parameters: {'min_child_samples': 10}. Best is trial 64 with value: 0.20588642989852504.\n",
      "\n",
      "min_child_samples, val_score: 0.205886:  40%|##   | 2/5 [00:03<00:05,  1.75s/it]\u001b[A\n",
      "min_child_samples, val_score: 0.205886:  40%|##   | 2/5 [00:05<00:05,  1.75s/it]\u001b[A\n",
      "min_child_samples, val_score: 0.205886:  60%|###  | 3/5 [00:05<00:03,  1.83s/it]\u001b[A[I 2024-02-06 20:43:15,175] Trial 65 finished with value: 0.20709715022395445 and parameters: {'min_child_samples': 50}. Best is trial 64 with value: 0.20588642989852504.\n",
      "\n",
      "min_child_samples, val_score: 0.205886:  60%|###  | 3/5 [00:05<00:03,  1.83s/it]\u001b[A\n",
      "min_child_samples, val_score: 0.205886:  60%|###  | 3/5 [00:07<00:03,  1.83s/it]\u001b[A\n",
      "min_child_samples, val_score: 0.205886:  80%|#### | 4/5 [00:07<00:01,  1.84s/it]\u001b[A[I 2024-02-06 20:43:17,020] Trial 66 finished with value: 0.20652970813833016 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 0.20588642989852504.\n",
      "\n",
      "min_child_samples, val_score: 0.205886:  80%|#### | 4/5 [00:07<00:01,  1.84s/it]\u001b[A\n",
      "min_child_samples, val_score: 0.205886:  80%|#### | 4/5 [00:08<00:01,  1.84s/it]\u001b[A\n",
      "min_child_samples, val_score: 0.205886: 100%|#####| 5/5 [00:08<00:00,  1.76s/it]\u001b[A[I 2024-02-06 20:43:18,647] Trial 67 finished with value: 0.20859961286213843 and parameters: {'min_child_samples': 100}. Best is trial 64 with value: 0.20588642989852504.\n",
      "min_child_samples, val_score: 0.205886: 100%|#####| 5/5 [00:08<00:00,  1.78s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "gbt_data = train_series.merge(forecast, on='ds', how='left')\n",
    "train_gbt, val_gbt = train_test_split(gbt_data, test_size=0.15, random_state=42)\n",
    "\n",
    "lgbm_wl = OptunaLGBMRegressor(n_estimators=300, learning_rate=0.01, metric='mape', seed=42)\n",
    "\n",
    "lgbm_wl.fit(\n",
    "    train_gbt.drop(['ds', 'y'], axis=1), \n",
    "    train_gbt.y.values,\n",
    "    val_gbt.drop(['ds', 'y'], axis=1),\n",
    "    val_gbt.y.values\n",
    ")\n",
    "\n",
    "test_gbt = new_test_series.merge(forecast, on='ds', how='left')\n",
    "preds = lgbm_wl.predict(test_gbt.drop(['ds'], axis=1)) # preds = lgbm.predict(test_gbt.drop(['ds', 'y'], axis=1))\n",
    "\n",
    "forecast_df = test_gbt[['ds']].copy() # forecast_df = test_gbt[['ds', 'y', 'yhat']].copy()\n",
    "forecast_df['gbt_yhat'] = preds\n",
    "\n",
    "# forecast_df['gbt_yhat'] - предикт модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'model_wl.h5py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/Users/andreyboriskin/PycharmProjects/predprof/models/model_wl/' + filename, 'wb') as file:\n",
    "\tpickle.dump(lgbm_wl, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ветер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_vt = df.copy()\n",
    "df_vt = df_vt.rename(columns={'Средняя скорость ветра': 'y'})\n",
    "df_vt.drop(df_vt.loc[df_vt['y'] == '  '].index, inplace=True)\n",
    "df_vt['y'] = df_vt['y'].astype('int64')\n",
    "data = pd.DataFrame(columns=['ds', 'y'])\n",
    "data['ds'] = df_vt.date\n",
    "data['y'] = df_vt.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_series = data # [data.ds < (data.ds.max() - timedelta(days=30))]\n",
    "# test_series = data[data.ds >= (data.ds.max() - timedelta(days=30))].drop(['y'], axis=1)\n",
    "start_date = '2022-12-31'\n",
    "end_date = '2023-01-07'\n",
    "\n",
    "start = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "end = datetime.strptime(end_date, '%Y-%m-%d')   \n",
    "\n",
    "daterange = [(start + timedelta(days=x)).strftime('%Y-%m-%d') for x in range(0, (end-start).days)]\n",
    "new_test_series = pd.DataFrame(pd.to_datetime(daterange), columns=['ds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:43:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "20:43:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "num_leaves, val_score: 0.749178:  55%|#####5    | 11/20 [08:19<06:48, 45.40s/it]\n"
     ]
    }
   ],
   "source": [
    "fb_vt = prophet.Prophet()\n",
    "\n",
    "with suppress_stdout_stderr():\n",
    "    fb_vt.fit(train_series)\n",
    "\n",
    "predictions = fb_vt.make_future_dataframe(periods=len(new_test_series), freq='D')\n",
    "forecast = fb_vt.predict(predictions)\n",
    "\n",
    "# v_fb_df = test_series.copy()\n",
    "# v_fb_df = v_fb_df.merge(forecast[['ds', 'yhat']], on='ds', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'fb_model_vt.h5py'\n",
    "with open('/Users/andreyboriskin/PycharmProjects/predprof/models/model_vt/' + filename, 'wb') as file:\n",
    "\tpickle.dump(fb_vt, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-06 20:43:23,545] A new study created in memory with name: no-name-f4316c2f-6a20-4680-9efc-a2d48da4fbfd\n",
      "feature_fraction, val_score: 0.548547:  14%|8     | 1/7 [00:00<00:03,  1.60it/s][I 2024-02-06 20:43:24,170] Trial 0 finished with value: 0.548546924616191 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.548546924616191.\n",
      "feature_fraction, val_score: 0.548314:  29%|#7    | 2/7 [00:01<00:03,  1.56it/s][I 2024-02-06 20:43:24,820] Trial 1 finished with value: 0.5483135361609164 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.5483135361609164.\n",
      "feature_fraction, val_score: 0.548314:  43%|##5   | 3/7 [00:01<00:02,  1.67it/s][I 2024-02-06 20:43:25,369] Trial 2 finished with value: 0.5483808766156537 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.5483135361609164.\n",
      "feature_fraction, val_score: 0.548247:  57%|###4  | 4/7 [00:02<00:01,  1.67it/s][I 2024-02-06 20:43:25,970] Trial 3 finished with value: 0.5482466990098123 and parameters: {'feature_fraction': 0.6}. Best is trial 3 with value: 0.5482466990098123.\n",
      "feature_fraction, val_score: 0.548112:  71%|####2 | 5/7 [00:03<00:01,  1.63it/s][I 2024-02-06 20:43:26,615] Trial 4 finished with value: 0.5481121510799276 and parameters: {'feature_fraction': 1.0}. Best is trial 4 with value: 0.5481121510799276.\n",
      "feature_fraction, val_score: 0.547959:  86%|#####1| 6/7 [00:03<00:00,  1.57it/s][I 2024-02-06 20:43:27,287] Trial 5 finished with value: 0.5479587845728653 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 5 with value: 0.5479587845728653.\n",
      "feature_fraction, val_score: 0.547959: 100%|######| 7/7 [00:04<00:00,  1.61it/s][I 2024-02-06 20:43:27,880] Trial 6 finished with value: 0.5481202747389899 and parameters: {'feature_fraction': 0.5}. Best is trial 5 with value: 0.5479587845728653.\n",
      "feature_fraction, val_score: 0.547959: 100%|######| 7/7 [00:04<00:00,  1.61it/s]\n",
      "num_leaves, val_score: 0.547959:   5%|5          | 1/20 [00:00<00:16,  1.12it/s][I 2024-02-06 20:43:28,774] Trial 7 finished with value: 0.5487600277763122 and parameters: {'num_leaves': 55}. Best is trial 7 with value: 0.5487600277763122.\n",
      "num_leaves, val_score: 0.547959:  10%|#1         | 2/20 [00:02<00:21,  1.19s/it][I 2024-02-06 20:43:30,169] Trial 8 finished with value: 0.54913580860743 and parameters: {'num_leaves': 120}. Best is trial 7 with value: 0.5487600277763122.\n",
      "num_leaves, val_score: 0.547959:  15%|#6         | 3/20 [00:03<00:16,  1.02it/s][I 2024-02-06 20:43:30,892] Trial 9 finished with value: 0.5484000841408405 and parameters: {'num_leaves': 37}. Best is trial 9 with value: 0.5484000841408405.\n",
      "num_leaves, val_score: 0.547959:  20%|##2        | 4/20 [00:05<00:24,  1.50s/it][I 2024-02-06 20:43:33,205] Trial 10 finished with value: 0.5508656000554303 and parameters: {'num_leaves': 253}. Best is trial 9 with value: 0.5484000841408405.\n",
      "num_leaves, val_score: 0.547959:  25%|##7        | 5/20 [00:07<00:26,  1.79s/it][I 2024-02-06 20:43:35,505] Trial 11 finished with value: 0.5508656000554303 and parameters: {'num_leaves': 253}. Best is trial 9 with value: 0.5484000841408405.\n",
      "num_leaves, val_score: 0.547959:  30%|###3       | 6/20 [00:09<00:24,  1.75s/it][I 2024-02-06 20:43:37,190] Trial 12 finished with value: 0.5484448358896581 and parameters: {'num_leaves': 165}. Best is trial 9 with value: 0.5484000841408405.\n",
      "num_leaves, val_score: 0.547959:  35%|###8       | 7/20 [00:11<00:22,  1.74s/it][I 2024-02-06 20:43:38,896] Trial 13 finished with value: 0.54883978984875 and parameters: {'num_leaves': 160}. Best is trial 9 with value: 0.5484000841408405.\n",
      "num_leaves, val_score: 0.547959:  40%|####4      | 8/20 [00:11<00:15,  1.26s/it][I 2024-02-06 20:43:39,143] Trial 14 finished with value: 0.5501684218600564 and parameters: {'num_leaves': 4}. Best is trial 9 with value: 0.5484000841408405.\n",
      "num_leaves, val_score: 0.547959:  45%|####9      | 9/20 [00:12<00:14,  1.28s/it][I 2024-02-06 20:43:40,466] Trial 15 finished with value: 0.5487297480329524 and parameters: {'num_leaves': 112}. Best is trial 9 with value: 0.5484000841408405.\n",
      "num_leaves, val_score: 0.547959:  50%|#####     | 10/20 [00:14<00:14,  1.49s/it][I 2024-02-06 20:43:42,418] Trial 16 finished with value: 0.5495045240549352 and parameters: {'num_leaves': 202}. Best is trial 9 with value: 0.5484000841408405.\n",
      "num_leaves, val_score: 0.547959:  55%|#####5    | 11/20 [00:15<00:12,  1.38s/it][I 2024-02-06 20:43:43,547] Trial 17 finished with value: 0.5484932125940222 and parameters: {'num_leaves': 84}. Best is trial 9 with value: 0.5484000841408405.\n",
      "num_leaves, val_score: 0.547959:  60%|######    | 12/20 [00:17<00:12,  1.54s/it][I 2024-02-06 20:43:45,464] Trial 18 finished with value: 0.5494105114659114 and parameters: {'num_leaves': 197}. Best is trial 9 with value: 0.5484000841408405.\n",
      "num_leaves, val_score: 0.547959:  65%|######5   | 13/20 [00:18<00:09,  1.42s/it][I 2024-02-06 20:43:46,602] Trial 19 finished with value: 0.5485475136071148 and parameters: {'num_leaves': 87}. Best is trial 9 with value: 0.5484000841408405.\n",
      "num_leaves, val_score: 0.547959:  70%|#######   | 14/20 [00:19<00:06,  1.15s/it][I 2024-02-06 20:43:47,132] Trial 20 finished with value: 0.5481634295482104 and parameters: {'num_leaves': 17}. Best is trial 20 with value: 0.5481634295482104.\n",
      "num_leaves, val_score: 0.547959:  75%|#######5  | 15/20 [00:21<00:06,  1.37s/it][I 2024-02-06 20:43:48,999] Trial 21 finished with value: 0.549898996096068 and parameters: {'num_leaves': 204}. Best is trial 20 with value: 0.5481634295482104.\n",
      "num_leaves, val_score: 0.547959:  80%|########  | 16/20 [00:22<00:04,  1.25s/it][I 2024-02-06 20:43:49,975] Trial 22 finished with value: 0.5487905910143087 and parameters: {'num_leaves': 66}. Best is trial 20 with value: 0.5481634295482104.\n",
      "num_leaves, val_score: 0.547959:  85%|########5 | 17/20 [00:23<00:04,  1.35s/it][I 2024-02-06 20:43:51,555] Trial 23 finished with value: 0.548573420214241 and parameters: {'num_leaves': 147}. Best is trial 20 with value: 0.5481634295482104.\n",
      "num_leaves, val_score: 0.547959:  90%|######### | 18/20 [00:25<00:02,  1.46s/it][I 2024-02-06 20:43:53,282] Trial 24 finished with value: 0.5490674481085368 and parameters: {'num_leaves': 182}. Best is trial 20 with value: 0.5481634295482104.\n",
      "num_leaves, val_score: 0.547959:  95%|#########5| 19/20 [00:27<00:01,  1.64s/it][I 2024-02-06 20:43:55,347] Trial 25 finished with value: 0.5500545530358691 and parameters: {'num_leaves': 217}. Best is trial 20 with value: 0.5481634295482104.\n",
      "num_leaves, val_score: 0.547959: 100%|##########| 20/20 [00:29<00:00,  1.78s/it][I 2024-02-06 20:43:57,441] Trial 26 finished with value: 0.5499541197923662 and parameters: {'num_leaves': 226}. Best is trial 20 with value: 0.5481634295482104.\n",
      "num_leaves, val_score: 0.547959: 100%|##########| 20/20 [00:29<00:00,  1.48s/it]\n",
      "bagging, val_score: 0.546458:  10%|#4            | 1/10 [00:00<00:07,  1.26it/s][I 2024-02-06 20:43:58,233] Trial 27 finished with value: 0.5464581491403199 and parameters: {'bagging_fraction': 0.4168834060909718, 'bagging_freq': 6}. Best is trial 27 with value: 0.5464581491403199.\n",
      "bagging, val_score: 0.546057:  20%|##8           | 2/10 [00:01<00:06,  1.26it/s][I 2024-02-06 20:43:59,026] Trial 28 finished with value: 0.5460572676589299 and parameters: {'bagging_fraction': 0.4181528081226307, 'bagging_freq': 6}. Best is trial 28 with value: 0.5460572676589299.\n",
      "bagging, val_score: 0.545001:  30%|####2         | 3/10 [00:02<00:05,  1.27it/s][I 2024-02-06 20:43:59,814] Trial 29 finished with value: 0.5450005324976486 and parameters: {'bagging_fraction': 0.4028644796034263, 'bagging_freq': 6}. Best is trial 29 with value: 0.5450005324976486.\n",
      "bagging, val_score: 0.545001:  40%|#####6        | 4/10 [00:03<00:04,  1.27it/s][I 2024-02-06 20:44:00,602] Trial 30 finished with value: 0.5463045674129586 and parameters: {'bagging_fraction': 0.41937353331521965, 'bagging_freq': 6}. Best is trial 29 with value: 0.5450005324976486.\n",
      "bagging, val_score: 0.545001:  50%|#######       | 5/10 [00:03<00:03,  1.26it/s][I 2024-02-06 20:44:01,404] Trial 31 finished with value: 0.546015515138086 and parameters: {'bagging_fraction': 0.4117071386602784, 'bagging_freq': 6}. Best is trial 29 with value: 0.5450005324976486.\n",
      "bagging, val_score: 0.545001:  60%|########4     | 6/10 [00:04<00:03,  1.26it/s][I 2024-02-06 20:44:02,194] Trial 32 finished with value: 0.5456888751336654 and parameters: {'bagging_fraction': 0.40741798304708504, 'bagging_freq': 6}. Best is trial 29 with value: 0.5450005324976486.\n",
      "bagging, val_score: 0.545001:  70%|#########7    | 7/10 [00:05<00:02,  1.27it/s][I 2024-02-06 20:44:02,974] Trial 33 finished with value: 0.5455132316112098 and parameters: {'bagging_fraction': 0.40174909540799464, 'bagging_freq': 6}. Best is trial 29 with value: 0.5450005324976486.\n",
      "bagging, val_score: 0.545001:  80%|###########2  | 8/10 [00:06<00:01,  1.25it/s][I 2024-02-06 20:44:03,800] Trial 34 finished with value: 0.5452721429898221 and parameters: {'bagging_fraction': 0.40951517640223367, 'bagging_freq': 6}. Best is trial 29 with value: 0.5450005324976486.\n",
      "bagging, val_score: 0.545001:  90%|############6 | 9/10 [00:07<00:00,  1.25it/s][I 2024-02-06 20:44:04,598] Trial 35 finished with value: 0.5464050192934184 and parameters: {'bagging_fraction': 0.40386392542067034, 'bagging_freq': 4}. Best is trial 29 with value: 0.5450005324976486.\n",
      "bagging, val_score: 0.545001: 100%|#############| 10/10 [00:07<00:00,  1.24it/s][I 2024-02-06 20:44:05,416] Trial 36 finished with value: 0.5465883661352564 and parameters: {'bagging_fraction': 0.6184632561139927, 'bagging_freq': 7}. Best is trial 29 with value: 0.5450005324976486.\n",
      "bagging, val_score: 0.545001: 100%|#############| 10/10 [00:07<00:00,  1.25it/s]\n",
      "feature_fraction_stage2, val_score: 0.545001:  17%|1| 1/6 [00:00<00:03,  1.27it/[I 2024-02-06 20:44:06,205] Trial 37 finished with value: 0.5450005324976486 and parameters: {'feature_fraction': 0.852}. Best is trial 37 with value: 0.5450005324976486.\n",
      "feature_fraction_stage2, val_score: 0.545001:  33%|3| 2/6 [00:01<00:03,  1.27it/[I 2024-02-06 20:44:06,991] Trial 38 finished with value: 0.5450005324976486 and parameters: {'feature_fraction': 0.8839999999999999}. Best is trial 37 with value: 0.5450005324976486.\n",
      "feature_fraction_stage2, val_score: 0.545001:  50%|5| 3/6 [00:02<00:02,  1.28it/[I 2024-02-06 20:44:07,768] Trial 39 finished with value: 0.5452844358149858 and parameters: {'feature_fraction': 0.9159999999999999}. Best is trial 37 with value: 0.5450005324976486.\n",
      "feature_fraction_stage2, val_score: 0.545001:  67%|6| 4/6 [00:03<00:01,  1.27it/[I 2024-02-06 20:44:08,556] Trial 40 finished with value: 0.5455851989940845 and parameters: {'feature_fraction': 0.9799999999999999}. Best is trial 37 with value: 0.5450005324976486.\n",
      "feature_fraction_stage2, val_score: 0.545001:  83%|8| 5/6 [00:03<00:00,  1.28it/[I 2024-02-06 20:44:09,334] Trial 41 finished with value: 0.5453254953043318 and parameters: {'feature_fraction': 0.82}. Best is trial 37 with value: 0.5450005324976486.\n",
      "feature_fraction_stage2, val_score: 0.545001: 100%|#| 6/6 [00:04<00:00,  1.27it/[I 2024-02-06 20:44:10,129] Trial 42 finished with value: 0.5452844358149858 and parameters: {'feature_fraction': 0.948}. Best is trial 37 with value: 0.5450005324976486.\n",
      "feature_fraction_stage2, val_score: 0.545001: 100%|#| 6/6 [00:04<00:00,  1.27it/\n",
      "regularization_factors, val_score: 0.545001:   5%| | 1/20 [00:00<00:15,  1.24it/[I 2024-02-06 20:44:10,940] Trial 43 finished with value: 0.5450005286745035 and parameters: {'lambda_l1': 1.2320651502978506e-05, 'lambda_l2': 1.8353664820538426e-05}. Best is trial 43 with value: 0.5450005286745035.\n",
      "regularization_factors, val_score: 0.545001:  10%|1| 2/20 [00:01<00:14,  1.24it/[I 2024-02-06 20:44:11,749] Trial 44 finished with value: 0.5450005297475526 and parameters: {'lambda_l1': 1.1013025979566606e-05, 'lambda_l2': 1.1331922282212597e-05}. Best is trial 43 with value: 0.5450005286745035.\n",
      "regularization_factors, val_score: 0.545001:  15%|1| 3/20 [00:02<00:13,  1.23it/[I 2024-02-06 20:44:12,566] Trial 45 finished with value: 0.5450005282150028 and parameters: {'lambda_l1': 2.5024429598677944e-05, 'lambda_l2': 1.1115854906323045e-05}. Best is trial 45 with value: 0.5450005282150028.\n",
      "regularization_factors, val_score: 0.545001:  20%|2| 4/20 [00:03<00:13,  1.23it/[I 2024-02-06 20:44:13,379] Trial 46 finished with value: 0.545000529833425 and parameters: {'lambda_l1': 1.317529071548596e-05, 'lambda_l2': 8.83864114098882e-06}. Best is trial 45 with value: 0.5450005282150028.\n",
      "regularization_factors, val_score: 0.545001:  25%|2| 5/20 [00:04<00:12,  1.23it/[I 2024-02-06 20:44:14,190] Trial 47 finished with value: 0.5450005305559953 and parameters: {'lambda_l1': 7.254109176500373e-06, 'lambda_l2': 8.456662949726852e-06}. Best is trial 45 with value: 0.5450005282150028.\n",
      "regularization_factors, val_score: 0.545001:  30%|3| 6/20 [00:04<00:11,  1.23it/[I 2024-02-06 20:44:15,001] Trial 48 finished with value: 0.5450005296490673 and parameters: {'lambda_l1': 1.3559492006510955e-05, 'lambda_l2': 9.935156097050712e-06}. Best is trial 45 with value: 0.5450005282150028.\n",
      "regularization_factors, val_score: 0.545001:  35%|3| 7/20 [00:05<00:10,  1.24it/[I 2024-02-06 20:44:15,795] Trial 49 finished with value: 0.5450005294096162 and parameters: {'lambda_l1': 1.5305596664727747e-05, 'lambda_l2': 1.0277675501153216e-05}. Best is trial 45 with value: 0.5450005282150028.\n",
      "regularization_factors, val_score: 0.545001:  40%|4| 8/20 [00:06<00:09,  1.24it/[I 2024-02-06 20:44:16,606] Trial 50 finished with value: 0.5450005290590713 and parameters: {'lambda_l1': 1.5685760370798287e-05, 'lambda_l2': 1.2617996850890285e-05}. Best is trial 45 with value: 0.5450005282150028.\n",
      "regularization_factors, val_score: 0.545001:  45%|4| 9/20 [00:07<00:08,  1.24it/[I 2024-02-06 20:44:17,416] Trial 51 finished with value: 0.5450005287651372 and parameters: {'lambda_l1': 1.901583567122459e-05, 'lambda_l2': 1.209182262137545e-05}. Best is trial 45 with value: 0.5450005282150028.\n",
      "regularization_factors, val_score: 0.545001:  50%|5| 10/20 [00:08<00:08,  1.23it[I 2024-02-06 20:44:18,239] Trial 52 finished with value: 0.5450005287274667 and parameters: {'lambda_l1': 2.143259538930037e-05, 'lambda_l2': 1.027373688801175e-05}. Best is trial 45 with value: 0.5450005282150028.\n",
      "regularization_factors, val_score: 0.545001:  55%|5| 11/20 [00:08<00:07,  1.22it[I 2024-02-06 20:44:19,076] Trial 53 finished with value: 0.5450005269716297 and parameters: {'lambda_l1': 3.284312197465658e-05, 'lambda_l2': 1.3928311594344161e-05}. Best is trial 53 with value: 0.5450005269716297.\n",
      "regularization_factors, val_score: 0.545001:  60%|6| 12/20 [00:09<00:06,  1.22it[I 2024-02-06 20:44:19,896] Trial 54 finished with value: 0.5450005196353536 and parameters: {'lambda_l1': 8.97236907144762e-05, 'lambda_l2': 2.139482848951848e-05}. Best is trial 54 with value: 0.5450005196353536.\n",
      "regularization_factors, val_score: 0.545001:  65%|6| 13/20 [00:10<00:05,  1.21it[I 2024-02-06 20:44:20,727] Trial 55 finished with value: 0.5452361438393766 and parameters: {'lambda_l1': 0.007331409694032998, 'lambda_l2': 0.0010414086266291934}. Best is trial 54 with value: 0.5450005196353536.\n",
      "regularization_factors, val_score: 0.545001:  70%|7| 14/20 [00:11<00:04,  1.21it[I 2024-02-06 20:44:21,549] Trial 56 finished with value: 0.5455673207397308 and parameters: {'lambda_l1': 0.00021714801618928384, 'lambda_l2': 1.3428410172172221e-08}. Best is trial 54 with value: 0.5450005196353536.\n",
      "regularization_factors, val_score: 0.545001:  75%|7| 15/20 [00:12<00:04,  1.22it[I 2024-02-06 20:44:22,358] Trial 57 finished with value: 0.5450005211717759 and parameters: {'lambda_l1': 2.8786343253044218e-08, 'lambda_l2': 8.514884084157985e-05}. Best is trial 54 with value: 0.5450005196353536.\n",
      "regularization_factors, val_score: 0.545001:  80%|8| 16/20 [00:13<00:03,  1.22it[I 2024-02-06 20:44:23,179] Trial 58 finished with value: 0.5455673142210097 and parameters: {'lambda_l1': 7.690172072426766e-08, 'lambda_l2': 0.00021500865626577798}. Best is trial 54 with value: 0.5450005196353536.\n",
      "regularization_factors, val_score: 0.545001:  85%|8| 17/20 [00:13<00:02,  1.22it[I 2024-02-06 20:44:23,995] Trial 59 finished with value: 0.5450005052373963 and parameters: {'lambda_l1': 6.136230379690942e-08, 'lambda_l2': 0.00020495744482551157}. Best is trial 59 with value: 0.5450005052373963.\n",
      "regularization_factors, val_score: 0.545001:  90%|9| 18/20 [00:14<00:01,  1.22it[I 2024-02-06 20:44:24,810] Trial 60 finished with value: 0.5450005055904411 and parameters: {'lambda_l1': 1.0491494297227841e-08, 'lambda_l2': 0.00020232642196777017}. Best is trial 59 with value: 0.5450005052373963.\n",
      "regularization_factors, val_score: 0.545001:  95%|9| 19/20 [00:15<00:00,  1.22it[I 2024-02-06 20:44:25,625] Trial 61 finished with value: 0.545567303051924 and parameters: {'lambda_l1': 1.1747818787930372e-08, 'lambda_l2': 0.0002863861732441246}. Best is trial 59 with value: 0.5450005052373963.\n",
      "regularization_factors, val_score: 0.545001: 100%|#| 20/20 [00:16<00:00,  1.23it[I 2024-02-06 20:44:26,426] Trial 62 finished with value: 0.5455673144332995 and parameters: {'lambda_l1': 1.385406675995394e-07, 'lambda_l2': 0.0002136273874368296}. Best is trial 59 with value: 0.5450005052373963.\n",
      "regularization_factors, val_score: 0.545001: 100%|#| 20/20 [00:16<00:00,  1.23it\n",
      "min_child_samples, val_score: 0.545001:  20%|#    | 1/5 [00:00<00:03,  1.28it/s][I 2024-02-06 20:44:27,213] Trial 63 finished with value: 0.5457088239035457 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.5457088239035457.\n",
      "min_child_samples, val_score: 0.545001:  40%|##   | 2/5 [00:01<00:02,  1.17it/s][I 2024-02-06 20:44:28,115] Trial 64 finished with value: 0.5454118280283674 and parameters: {'min_child_samples': 50}. Best is trial 64 with value: 0.5454118280283674.\n",
      "min_child_samples, val_score: 0.544751:  60%|###  | 3/5 [00:02<00:01,  1.08it/s][I 2024-02-06 20:44:29,129] Trial 65 finished with value: 0.5447509970477208 and parameters: {'min_child_samples': 100}. Best is trial 65 with value: 0.5447509970477208.\n",
      "min_child_samples, val_score: 0.544751:  80%|#### | 4/5 [00:03<00:00,  1.13it/s][I 2024-02-06 20:44:29,946] Trial 66 finished with value: 0.5451270595020703 and parameters: {'min_child_samples': 25}. Best is trial 65 with value: 0.5447509970477208.\n",
      "min_child_samples, val_score: 0.544751: 100%|#####| 5/5 [00:04<00:00,  1.20it/s][I 2024-02-06 20:44:30,695] Trial 67 finished with value: 0.5466220482834909 and parameters: {'min_child_samples': 5}. Best is trial 65 with value: 0.5447509970477208.\n",
      "min_child_samples, val_score: 0.544751: 100%|#####| 5/5 [00:04<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "gbt_data = train_series.merge(forecast, on='ds', how='left')\n",
    "train_gbt, val_gbt = train_test_split(gbt_data, test_size=0.15, random_state=42)\n",
    "\n",
    "lgbm_vt = OptunaLGBMRegressor(n_estimators=300, learning_rate=0.01, metric='mape', seed=42)\n",
    "\n",
    "lgbm_vt.fit(\n",
    "    train_gbt.drop(['ds', 'y'], axis=1), \n",
    "    train_gbt.y.values,\n",
    "    val_gbt.drop(['ds', 'y'], axis=1),\n",
    "    val_gbt.y.values\n",
    ")\n",
    "\n",
    "test_gbt = new_test_series.merge(forecast, on='ds', how='left')\n",
    "preds = lgbm_vt.predict(test_gbt.drop(['ds'], axis=1)) # preds = lgbm.predict(test_gbt.drop(['ds', 'y'], axis=1))\n",
    "\n",
    "forecast_df = test_gbt[['ds']].copy() # forecast_df = test_gbt[['ds', 'y', 'yhat']].copy()\n",
    "forecast_df['gbt_yhat'] = preds\n",
    "\n",
    "# forecast_df['gbt_yhat'] - предикт модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'model_vt.h5py'\n",
    "\n",
    "with open('/Users/andreyboriskin/PycharmProjects/predprof/models/model_vt/' + filename, 'wb') as file:\n",
    "\tpickle.dump(lgbm_vt, file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
